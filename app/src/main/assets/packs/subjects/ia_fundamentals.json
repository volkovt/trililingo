{
  "packVersion": 1,
  "subjectId": "ai",
  "subjectName": "Intelig√™ncia Artificial",
  "tracks": [
    {
      "id": "ai_fundamentals",
      "title": "Fundamentos de IA",
      "subtitle": "Conceitos base para evoluir r√°pido",
      "enabled": true,
      "features": [
        {
          "id": "daily_challenge",
          "type": "DAILY_CHALLENGE",
          "title": "Desafio Di√°rio",
          "subtitle": "Perguntas do dia",
          "emoji": "‚ö°",
          "enabled": true
        },
        {
          "id": "free_study",
          "type": "STUDY",
          "title": "Estudo Livre",
          "subtitle": "Sess√£o aberta de estudo",
          "emoji": "üß†",
          "enabled": true
        }
      ],
      "studyContent": {
        "source": {
          "book": "Python para Data Science e Machine Learning descomplicado",
          "authors": [
            "Amilcar Netto",
            "Francisco Maciel"
          ],
          "mdOutline": "introdu√ßa√£o a machine learning.md",
          "language": "pt-BR"
        },
        "chapters": [
          {
            "chapter": 6,
            "id": "introducao_ml",
            "title": "Introdu√ß√£o ao Aprendizado de M√°quina",
            "keyTopics": [
              "Principais defini√ß√µes",
              "Intelig√™ncia Artificial",
              "Machine Learning",
              "Data Analysis",
              "Data Science",
              "Terminologia de estat√≠stica",
              "N√≠vel de confian√ßa e margem de erro",
              "Z-Score",
              "Etapas de um projeto de an√°lise de dados",
              "Defini√ß√£o do problema",
              "Prepara√ß√£o dos dados",
              "Extra√ß√£o e carga dos dados",
              "Explora√ß√£o e visualiza√ß√£o dos dados",
              "Transforma√ß√£o dos dados",
              "Escolha do algoritmo",
              "Aprendizagem supervisionada",
              "Regress√£o",
              "Classifica√ß√£o",
              "Aprendizagem n√£o supervisionada",
              "Verifica√ß√£o cruzada",
              "Overfitting e Underfitting",
              "Matriz de confus√£o",
              "M√©tricas",
              "Dilema vi√©s-vari√¢ncia"
            ],
            "questions": [
              {
                "id": "ch6_q01",
                "type": [
                  "ia",
                  "defini√ß√µes"
                ],
                "prompt": "Explique a diferen√ßa entre IA, Machine Learning e Deep Learning, dando um exemplo pr√°tico de aplica√ß√£o para cada um.",
                "difficulty": 3,
                "tags": [],
                "expected": "IA √© o ‚Äúguarda‚Äëchuva‚Äù (sistemas que parecem inteligentes). ML √© um subconjunto: aprende padr√µes a partir de dados. DL √© um subconjunto de ML: usa redes neurais profundas.\nExemplos: IA (planejamento de rotas), ML (detectar spam com dados rotulados), DL (reconhecer objetos em imagens)."
              },
              {
                "id": "ch6_q02",
                "type": [
                  "ia",
                  "ml"
                ],
                "prompt": "Compare Data Analysis, Data Science e Machine Learning. Onde cada um come√ßa e termina em um projeto real?",
                "difficulty": 3,
                "tags": [],
                "expected": "Data Analysis foca em descrever/explicar dados (m√©tricas, dashboards, hip√≥teses). Data Science inclui an√°lise + experimentos + modelagem + comunica√ß√£o. ML √© a parte de modelagem preditiva/automatiza√ß√£o.\nNum projeto: DA explora e mede, DS define abordagem e valida, ML entrega modelo/servi√ßo e monitoramento."
              },
              {
                "id": "ch6_q03",
                "type": [
                  "ml",
                  "defini√ß√µes"
                ],
                "prompt": "Defina 'amostra', 'feature', 'label/target' e 'vari√°vel de confus√£o'. Mostre como isso aparece em um dataset tabular.",
                "difficulty": 3,
                "tags": [],
                "expected": "Amostra = uma linha/observa√ß√£o. Features = colunas de entrada (X). Label/target = o que queremos prever (y). Vari√°vel de confus√£o = influencia X e y e pode criar correla√ß√£o enganosa.\nEx.: previs√£o de churn: amostra=cliente; features=uso, plano; target=churn; confus√£o=campanha de reten√ß√£o."
              },
              {
                "id": "ch6_q04",
                "type": [
                  "data_analysis",
                  "data_science"
                ],
                "prompt": "Explique os tr√™s grandes paradigmas de aprendizado (supervisionado, n√£o supervisionado e por refor√ßo) e quando escolher cada um.",
                "difficulty": 3,
                "tags": [],
                "expected": "Supervisionado: h√° r√≥tulos; objetivo √© prever (classifica√ß√£o/regress√£o). N√£o supervisionado: sem r√≥tulos; objetivo √© descobrir estrutura (clusters, redu√ß√£o de dimens√£o). Refor√ßo: agente aprende por recompensa em sequ√™ncia (pol√≠ticas).\nEscolha pelo tipo de dado/feedback dispon√≠vel e pela decis√£o que voc√™ quer automatizar."
              },
              {
                "id": "ch6_q05",
                "type": [
                  "ml",
                  "data_analysis"
                ],
                "prompt": "Por que separamos dados em treino/valida√ß√£o/teste? O que muda quando usamos cross-validation?",
                "difficulty": 3,
                "tags": [],
                "expected": "Treino ajusta par√¢metros; valida√ß√£o escolhe hiperpar√¢metros/decis√µes (ex.: threshold); teste estima performance ‚Äúfinal‚Äù em dados nunca vistos.\nCross-validation repete parti√ß√µes para reduzir vari√¢ncia da estimativa (melhor quando h√° pouco dado)."
              },
              {
                "id": "ch6_q06",
                "type": [
                  "estat√≠stica"
                ],
                "prompt": "Explique 'data leakage' com 3 exemplos comuns e como evit√°-los.",
                "difficulty": 4,
                "tags": [],
                "expected": "Leakage √© usar informa√ß√£o do futuro/da resposta durante treino/valida√ß√£o.\nExemplos: (1) normalizar com m√©dia/DP do dataset inteiro; (2) selecionar features usando todos os dados antes do split; (3) usar vari√°veis calculadas ap√≥s o evento (ex.: ‚Äòstatus_final‚Äô).\nEvitar com Pipeline/ColumnTransformer, split temporal quando necess√°rio e auditoria de features."
              },
              {
                "id": "ch6_q07",
                "type": [
                  "estat√≠stica",
                  "projeto"
                ],
                "prompt": "Descreva o trade-off vi√©s‚Äìvari√¢ncia (bias‚Äìvariance) e como ele se manifesta em underfitting e overfitting.",
                "difficulty": 3,
                "tags": [],
                "expected": "Vi√©s alto: modelo simples demais, erra sistematicamente (underfitting). Vari√¢ncia alta: modelo sens√≠vel a ru√≠do, performa bem no treino e mal no teste (overfitting).\nMitiga√ß√£o: mais dados, regulariza√ß√£o, valida√ß√£o correta, escolha de complexidade e features melhores."
              },
              {
                "id": "ch6_q08",
                "type": [
                  "estat√≠stica",
                  "zscore"
                ],
                "prompt": "O que √© baseline e por que ele √© obrigat√≥rio antes de modelos ‚Äúsofisticados‚Äù?",
                "difficulty": 2,
                "tags": [],
                "expected": "Baseline √© uma refer√™ncia simples (ex.: ‚Äúsempre prever a classe majorit√°ria‚Äù, regress√£o pela m√©dia, regra de neg√≥cio).\nEle mostra se o problema tem sinal; evita gastar tempo em modelos complexos sem ganho real e ajuda a justificar valor."
              },
              {
                "id": "ch6_q09",
                "type": [
                  "zscore",
                  "pr√©-processamento"
                ],
                "prompt": "Explique a diferen√ßa entre classifica√ß√£o e regress√£o. D√™ um exemplo em que a mesma tarefa pode ser modelada das duas formas.",
                "difficulty": 2,
                "tags": [],
                "expected": "Classifica√ß√£o prev√™ categorias; regress√£o prev√™ valores cont√≠nuos.\nEx.: cr√©dito: (a) classificar ‚Äúinadimplente vs n√£o‚Äù; (b) regressar probabilidade/score ou perda esperada (LGD/EL)."
              },
              {
                "id": "ch6_q10",
                "type": [
                  "projeto",
                  "pipeline"
                ],
                "prompt": "Monte uma matriz de confus√£o (TP, FP, TN, FN) e derive precis√£o, recall e F1. Interprete cada m√©trica.",
                "difficulty": 3,
                "tags": [],
                "expected": "Precis√£o = TP/(TP+FP): ‚Äúquando digo positivo, acerto?‚Äù. Recall = TP/(TP+FN): ‚Äúdos positivos reais, quantos capturei?‚Äù. F1 = harm√¥nica, equilibra precis√£o/recall.\nUse quando classes desbalanceadas e custo de erro importa."
              },
              {
                "id": "ch6_q11",
                "type": [
                  "projeto",
                  "defini√ß√£o"
                ],
                "prompt": "Quando ROC-AUC pode enganar? Compare ROC-AUC vs PR-AUC em cen√°rios desbalanceados.",
                "difficulty": 4,
                "tags": [],
                "expected": "ROC-AUC pode parecer alto mesmo com muitos falsos positivos quando a classe negativa domina.\nPR-AUC foca na classe positiva e evidencia o trade-off precis√£o/recall; costuma ser mais informativa em fraudes/intrus√£o/churn raro."
              },
              {
                "id": "ch6_q12",
                "type": [
                  "dados",
                  "prepara√ß√£o"
                ],
                "prompt": "Explique 'feature engineering' e d√™ 5 exemplos √∫teis em dados tabulares.",
                "difficulty": 3,
                "tags": [],
                "expected": "Feature engineering cria representa√ß√µes melhores do problema.\nEx.: log-transform em vari√°veis muito assim√©tricas; normaliza√ß√£o/standardiza√ß√£o; one-hot de categ√≥ricas; agrega√ß√µes por usu√°rio (m√©dia/contagem/janela temporal); intera√ß√µes (x1*x2) e datas (dia da semana)."
              },
              {
                "id": "ch6_q13",
                "type": [
                  "etl",
                  "dados"
                ],
                "prompt": "O que √© padroniza√ß√£o (StandardScaler) vs normaliza√ß√£o (MinMax)? Quando cada uma √© mais apropriada?",
                "difficulty": 3,
                "tags": [],
                "expected": "StandardScaler: z=(x-Œº)/œÉ, √∫til para modelos sens√≠veis a escala (SVM, KNN, regress√µes com regulariza√ß√£o). MinMax: coloca em [0,1], √∫til quando limites importam (redes neurais, dist√¢ncia com faixa controlada).\nA regra: se o modelo usa dist√¢ncia/gradiente, cuide da escala."
              },
              {
                "id": "ch6_q14",
                "type": [
                  "eda"
                ],
                "prompt": "Explique o conceito de 'pipeline' em ML e como ele ajuda a evitar bugs e leakage.",
                "difficulty": 3,
                "tags": [],
                "expected": "Pipeline encadeia pr√©-processamento + modelo numa √∫nica pe√ßa trein√°vel (fit) e reprodut√≠vel (transform/predict).\nEle garante que estat√≠sticas (m√©dia, encoder, sele√ß√£o) sejam aprendidas s√≥ no treino e aplicadas igual no teste/produ√ß√£o."
              },
              {
                "id": "ch6_q15",
                "type": [
                  "transforma√ß√£o"
                ],
                "prompt": "Quais s√£o as principais etapas de um projeto de ML do ponto de vista experimental (n√£o de c√≥digo)?",
                "difficulty": 3,
                "tags": [],
                "expected": "(1) Definir objetivo e m√©trica alinhada ao neg√≥cio; (2) obter/limpar dados; (3) EDA + hip√≥teses; (4) baseline; (5) treinar e validar; (6) tuning; (7) avalia√ß√£o final; (8) deploy; (9) monitorar drift/qualidade; (10) iterar."
              },
              {
                "id": "ch6_q16",
                "type": [
                  "supervisionada"
                ],
                "prompt": "Explique a diferen√ßa entre valida√ß√£o aleat√≥ria e valida√ß√£o temporal. Quando usar split temporal?",
                "difficulty": 4,
                "tags": [],
                "expected": "Valida√ß√£o aleat√≥ria assume i.i.d. (amostras independentes). Em s√©ries/produ√ß√£o, dados t√™m ordem e vazamento temporal √© comum.\nUse split temporal quando a predi√ß√£o ser√° feita no futuro (ex.: demanda, fraude ao longo do tempo) ou quando h√° drift."
              },
              {
                "id": "ch6_q17",
                "type": [
                  "regress√£o",
                  "classifica√ß√£o"
                ],
                "prompt": "O que s√£o hiperpar√¢metros vs par√¢metros? D√™ exemplos e como geralmente escolhemos cada um.",
                "difficulty": 3,
                "tags": [],
                "expected": "Par√¢metros s√£o aprendidos no treino (pesos, coeficientes). Hiperpar√¢metros controlam o aprendizado/complexidade (k no KNN, C e gamma no SVM, profundidade em √°rvore).\nEscolha hiperpar√¢metros via valida√ß√£o (grid/random/bayes) e mantenha teste isolado."
              },
              {
                "id": "ch6_q18",
                "type": [
                  "n√£o_supervisionada"
                ],
                "prompt": "Explique 'regulariza√ß√£o' (L1, L2) de forma intuitiva e cite um efeito colateral importante.",
                "difficulty": 4,
                "tags": [],
                "expected": "Regulariza√ß√£o penaliza modelos muito ‚Äúcomplexos‚Äù para reduzir overfitting. L2 encolhe coeficientes; L1 pode zerar coeficientes (sele√ß√£o).\nEfeito: coeficientes ficam menores e interpreta√ß√£o muda; precisa padronizar features para comparar penaliza√ß√£o corretamente."
              },
              {
                "id": "ch6_q19",
                "type": [
                  "valida√ß√£o",
                  "cross_validation"
                ],
                "prompt": "Como voc√™ lidaria com classes desbalanceadas? D√™ pelo menos 4 estrat√©gias e quando usar cada uma.",
                "difficulty": 4,
                "tags": [],
                "expected": "Estrat√©gias: (1) m√©tricas adequadas (PR/F1, recall@precision); (2) ajuste de threshold; (3) reamostragem (SMOTE/undersample); (4) pesos de classe; (5) coletar mais positivos; (6) detec√ß√£o de anomalia quando r√≥tulo √© raro.\nEscolha pelo custo de FP/FN e pelo volume de dados."
              },
              {
                "id": "ch6_q20",
                "type": [
                  "overfitting",
                  "underfitting"
                ],
                "prompt": "O que √© 'data drift' e 'concept drift'? Quais sinais de que o modelo precisa ser reavaliado?",
                "difficulty": 4,
                "tags": [],
                "expected": "Data drift: distribui√ß√£o de X muda (ex.: usu√°rios, sazonalidade). Concept drift: rela√ß√£o X‚Üíy muda (regra do mundo mudou).\nSinais: queda de m√©tricas online, aumento de erros em segmentos, mudan√ßas estat√≠sticas (PSI/KS), alertas de monitoramento e feedback humano."
              },
              {
                "id": "ch6_q21",
                "type": [
                  "matriz_confus√£o"
                ],
                "prompt": "Quais cuidados de reprodutibilidade voc√™ adotaria em um notebook de ML?",
                "difficulty": 3,
                "tags": [],
                "expected": "Fixar seeds (numpy/sklearn), registrar vers√µes (pip freeze), salvar splits e par√¢metros, usar pipelines, evitar estado oculto (executar do zero), logar m√©tricas e artefatos (model.pkl, gr√°ficos).\nReprodutibilidade √© pr√©‚Äërequisito para depurar e evoluir."
              },
              {
                "id": "ch6_q22",
                "type": [
                  "m√©tricas"
                ],
                "prompt": "Explique por que 'acur√°cia' pode mascarar erros em datasets desbalanceados. D√™ um exemplo num√©rico.",
                "difficulty": 3,
                "tags": [],
                "expected": "Se 99% √© classe 0, prever sempre 0 d√° 99% de acur√°cia, mas recall da classe 1 √© 0.\nEx.: 10.000 amostras, 100 positivas; modelo que prev√™ tudo negativo: accuracy=99%, recall=0%, precis√£o indefinida (0 TP)."
              },
              {
                "id": "ch6_q23",
                "type": [
                  "bias_variance"
                ],
                "prompt": "Explique a diferen√ßa entre valida√ß√£o, teste e monitoramento em produ√ß√£o. Por que 'teste' n√£o encerra o assunto?",
                "difficulty": 3,
                "tags": [],
                "expected": "Valida√ß√£o guia escolhas; teste mede generaliza√ß√£o offline; produ√ß√£o muda (dados e comportamento).\nMonitoramento detecta drift, degrada√ß√£o, bugs de pipeline e mudan√ßas de custo. Sem monitorar, o modelo ‚Äúenvelhece‚Äù silenciosamente."
              },
              {
                "id": "ch6_q24",
                "type": [
                  "m√©tricas",
                  "desbalanceamento"
                ],
                "prompt": "O que significa 'calibra√ß√£o' em modelos de classifica√ß√£o probabil√≠stica? Como verificar e corrigir?",
                "difficulty": 5,
                "tags": [],
                "expected": "Probabilidade calibrada: quando o modelo diz 0,7, ~70% desses casos s√£o positivos.\nVerifique com reliability diagram/Brier score. Corrija com Platt scaling, isotonic regression ou ajuste do modelo/regulariza√ß√£o."
              },
              {
                "id": "ch6_q25",
                "type": [
                  "ml",
                  "conceitos"
                ],
                "prompt": "Explique o conceito de 'custo de erro' e como ele muda a escolha de m√©trica e threshold.",
                "difficulty": 4,
                "tags": [],
                "expected": "FP e FN t√™m custos diferentes (fraude: FN caro; cr√©dito: FP pode negar bons clientes).\nEscolha m√©trica alinhada (recall, precision@recall, lucro esperado) e ajuste threshold para otimizar custo total, n√£o s√≥ F1/accuracy."
              },
              {
                "id": "ch6_q26",
                "type": [
                  "dados",
                  "split"
                ],
                "prompt": "Descreva como transformar um problema de neg√≥cio em um problema de ML (perguntas que voc√™ faria).",
                "difficulty": 4,
                "tags": [],
                "expected": "Pergunte: qual decis√£o ser√° tomada? qual alvo observ√°vel? qual horizonte? quais dados existem antes da decis√£o? qual m√©trica de sucesso? quais custos de erro? existe feedback/rotulagem? quais restri√ß√µes (lat√™ncia, explicabilidade)?\nIsso evita modelar a coisa ‚Äúerrada‚Äù."
              },
              {
                "id": "ch6_q27",
                "type": [
                  "pipeline",
                  "leakage"
                ],
                "prompt": "O que √© 'feature leakage' e como detect√°-lo sem olhar para o c√≥digo?",
                "difficulty": 4,
                "tags": [],
                "expected": "Feature leakage √© quando uma feature carrega indiretamente a resposta.\nSinais: m√©tricas absurdamente altas; import√¢ncia dominada por uma √∫nica coluna; feature ‚Äúfaz sentido‚Äù apenas ap√≥s o evento; correla√ß√£o quase perfeita com y; queda forte ao usar split temporal."
              },
              {
                "id": "ch6_q28",
                "type": [
                  "m√©tricas",
                  "confusao"
                ],
                "prompt": "Discuta interpretabilidade: quando voc√™ precisa explicar o modelo? Cite t√©cnicas para modelos lineares e n√£o lineares.",
                "difficulty": 4,
                "tags": [],
                "expected": "Precisa explicar em √°reas reguladas, decis√µes de alto impacto e quando h√° auditoria/depura√ß√£o.\nLineares: coeficientes, odds ratio, intervalos. N√£o lineares: feature importance, PDP/ICE, SHAP, LIME, regras extra√≠das e valida√ß√£o por casos."
              },
              {
                "id": "ch6_q29",
                "type": [
                  "m√©tricas",
                  "precision_recall"
                ],
                "prompt": "Como voc√™ validaria um modelo com dados de usu√°rios repetidos (m√∫ltiplas linhas por usu√°rio) para evitar vazamento?",
                "difficulty": 5,
                "tags": [],
                "expected": "Use split por grupo (GroupKFold / GroupShuffleSplit) para que o mesmo usu√°rio n√£o apare√ßa em treino e teste.\nCaso contr√°rio, o modelo memoriza padr√µes do usu√°rio e a m√©trica fica inflada."
              },
              {
                "id": "ch6_q30",
                "type": [
                  "m√©tricas",
                  "precision_recall"
                ],
                "prompt": "Explique a diferen√ßa entre 'correla√ß√£o' e 'causalidade' no contexto de ML e um risco pr√°tico dessa confus√£o.",
                "difficulty": 4,
                "tags": [],
                "expected": "ML aprende correla√ß√µes; isso n√£o prova causa. Ex.: ‚Äúusu√°rios com desconto churnam menos‚Äù pode ser porque desconto foi dado aos que j√° iam churnar (confounding).\nRisco: a√ß√µes de neg√≥cio baseadas no modelo podem falhar; para causalidade, precisa de experimento/quase‚Äëexperimento."
              },
              {
                "id": "ch6_q31",
                "type": [
                  "m√©tricas",
                  "f1"
                ],
                "prompt": "Descreva um mini-plano de experimento (em 6 passos) para comparar 2 modelos e escolher o melhor com rigor.",
                "difficulty": 4,
                "tags": [],
                "expected": "(1) Definir m√©trica e crit√©rio de decis√£o; (2) fixar protocolo de split/CV; (3) padronizar pipeline de pr√©-processamento; (4) treinar ambos com tuning compar√°vel; (5) avaliar no teste e analisar erros por segmento; (6) registrar resultados e validar com stakeholders."
              },
              {
                "id": "ch6_q32",
                "type": [
                  "estat√≠stica",
                  "zscore"
                ],
                "prompt": "Explique o que √© 'erro sistem√°tico' vs 'erro aleat√≥rio' em previs√µes e como diagnosticar cada um.",
                "difficulty": 4,
                "tags": [],
                "expected": "Sistem√°tico: padr√£o consistente de erro (ex.: subestimar valores altos), indica vi√©s/feature faltante. Aleat√≥rio: ru√≠do residual inevit√°vel.\nDiagn√≥stico: gr√°ficos de res√≠duos vs predito, an√°lise por faixa/segmento, inspe√ß√£o de casos e checagem de distribui√ß√£o de features."
              },
              {
                "id": "ch6_q33",
                "type": [
                  "bias_variance"
                ],
                "prompt": "Quais s√£o os riscos √©ticos mais comuns em ML e como mitig√°-los em um projeto real?",
                "difficulty": 4,
                "tags": [],
                "expected": "Riscos: vi√©s/discrimina√ß√£o, privacidade, uso fora do prop√≥sito, falta de explica√ß√£o, automa√ß√£o de decis√µes sens√≠veis.\nMitiga√ß√£o: revis√£o de dados (representatividade), m√©tricas por grupo, minimiza√ß√£o de dados, governan√ßa, explicabilidade, testes de fairness e auditoria cont√≠nua."
              },
              {
                "id": "ch6_q34",
                "type": [
                  "valida√ß√£o",
                  "baseline"
                ],
                "prompt": "Explique como voc√™ transformaria um modelo offline em um produto: requisitos de lat√™ncia, observabilidade e fallback.",
                "difficulty": 5,
                "tags": [],
                "expected": "Defina SLA (lat√™ncia), contrato de entrada/sa√≠da, versionamento de modelo, logs de features/predi√ß√µes, m√©tricas online, alertas e fallback (regra/baseline) se o modelo falhar.\nProduto de ML √© sistema: dados + modelo + opera√ß√£o."
              }
            ]
          },
          {
            "chapter": 7,
            "id": "bibliotecas_data_science",
            "title": "Bibliotecas para Data Science",
            "keyTopics": [
              "Pandas: carregar arquivo, Series, head/tail, shape/len, dtypes, iloc/loc, missing values, pivot",
              "nulos, drop, lambda, sum, count non-null",
              "gr√°ficos estat√≠sticos com pandas (linhas, scatter, barras, linhas m√∫ltiplas, barras empilhadas, histograma)",
              "salvar dataframe",
              "Pandas Profiling (intera√ß√µes, correla√ß√£o, missing stats, amostras)",
              "NumPy (arrays, reshape, opera√ß√µes aritm√©ticas)",
              "Scikit-Learn"
            ],
            "questions": [
              {
                "id": "ch7_q01",
                "type": [
                  "pandas"
                ],
                "prompt": "Explique por que NumPy √© a base do ecossistema de Data Science em Python. Compare array NumPy vs lista Python em desempenho e mem√≥ria.",
                "difficulty": 3,
                "tags": [],
                "expected": "NumPy fornece arrays homog√™neos e opera√ß√µes vetorizadas em C, reduzindo overhead de loops Python.\nListas guardam ponteiros para objetos; arrays guardam blocos cont√≠guos tipados. Por isso, somas/multiplica√ß√µes em NumPy s√£o muito mais r√°pidas e previs√≠veis em mem√≥ria."
              },
              {
                "id": "ch7_q02",
                "type": [
                  "pandas",
                  "io"
                ],
                "prompt": "O que √© 'broadcasting' no NumPy? D√™ um exemplo e explique um erro comum causado por shapes incompat√≠veis.",
                "difficulty": 4,
                "tags": [],
                "expected": "Broadcasting permite operar arrays de shapes diferentes seguindo regras (dimens√£o 1 ‚Äúexpande‚Äù).\nEx.: (100,3) + (3,) soma vetor a cada linha. Erro comum: tentar somar (100,3) com (100,) achando que soma por linha; na verdade o shape n√£o alinha e gera ValueError."
              },
              {
                "id": "ch7_q03",
                "type": [
                  "pandas",
                  "series"
                ],
                "prompt": "Explique o papel de Pandas. Quando voc√™ escolheria Pandas vs NumPy puro?",
                "difficulty": 3,
                "tags": [],
                "expected": "Pandas adiciona r√≥tulos (√≠ndices/colunas), tipos heterog√™neos, join/groupby e IO (CSV/Excel/SQL). √â ideal para dados tabulares e limpeza.\nNumPy puro √© melhor para c√°lculo num√©rico intenso, matrizes grandes e opera√ß√µes vetorizadas sem necessidade de r√≥tulos."
              },
              {
                "id": "ch7_q04",
                "type": [
                  "pandas",
                  "eda"
                ],
                "prompt": "Leia um CSV grande: quais op√ß√µes do pandas.read_csv ajudam desempenho e consist√™ncia de tipos?",
                "difficulty": 4,
                "tags": [],
                "expected": "Use: dtype=‚Ä¶ para evitar infer√™ncia cara, parse_dates para datas, usecols para reduzir colunas, chunksize para streaming, na_values para missing.\nTamb√©m √© comum usar low_memory=False (com cuidado) e encoding/sep corretos para evitar parsing inconsistente."
              },
              {
                "id": "ch7_q05",
                "type": [
                  "pandas"
                ],
                "prompt": "Diferen√ßa entre .loc e .iloc no Pandas. D√™ exemplos com slicing e filtros booleanos.",
                "difficulty": 3,
                "tags": [],
                "expected": ".loc usa r√≥tulos (√≠ndice/nomes de colunas) e √© inclusivo em labels; .iloc usa posi√ß√µes inteiras e slicing padr√£o (fim exclusivo).\nEx.: df.loc[df['idade']>30, ['nome','salario']] vs df.iloc[0:10, 0:3]."
              },
              {
                "id": "ch7_q06",
                "type": [
                  "pandas",
                  "tipos"
                ],
                "prompt": "Explique o que √© um 'index' no Pandas e quando faz sentido defini-lo explicitamente.",
                "difficulty": 3,
                "tags": [],
                "expected": "Index identifica linhas; pode ser RangeIndex (0..n) ou uma chave (id, data). Index bem escolhido melhora joins, alinhamentos e consultas por label.\nDefina quando h√° chave natural est√°vel (user_id, timestamp) e voc√™ quer opera√ß√µes por label, resample ou merge mais claro."
              },
              {
                "id": "ch7_q07",
                "type": [
                  "pandas",
                  "indexa√ß√£o"
                ],
                "prompt": "Quais s√£o as formas mais comuns de valores ausentes (NaN, None, strings vazias)? Como padronizar e tratar missing de forma correta?",
                "difficulty": 4,
                "tags": [],
                "expected": "Missing pode vir como NaN, None, '', 'NA', 'null'. Padronize via na_values no read_csv ou replace.\nTratamento: remover (quando pouco), imputar (m√©dia/mediana/moda), criar indicador de missing e entender causa (MCAR/MAR/MNAR) para n√£o enviesar."
              },
              {
                "id": "ch7_q08",
                "type": [
                  "pandas",
                  "missing"
                ],
                "prompt": "Explique groupby no Pandas e d√™ um exemplo de agrega√ß√µes m√∫ltiplas (mean, count, std) por grupo.",
                "difficulty": 3,
                "tags": [],
                "expected": "groupby divide dados por chave e aplica agrega√ß√µes.\nEx.: df.groupby('cidade')['preco'].agg(['mean','count','std']). Isso √© base para features por usu√°rio (m√©dia, frequ√™ncia, vari√¢ncia)."
              },
              {
                "id": "ch7_q09",
                "type": [
                  "pandas",
                  "missing"
                ],
                "prompt": "Compare merge/join/concat no Pandas. Quais armadilhas voc√™ checaria ap√≥s um merge?",
                "difficulty": 4,
                "tags": [],
                "expected": "concat empilha (linhas/colunas) sem ‚Äúchave‚Äù; merge/join combina por chave (inner/left/right/outer).\nArmadilhas: duplicidade de chaves (explode linhas), chaves com tipos diferentes, missing em chaves e colunas com mesmo nome (suffixes). Valide counts antes/depois."
              },
              {
                "id": "ch7_q10",
                "type": [
                  "pandas",
                  "limpeza"
                ],
                "prompt": "Explique diferen√ßa entre apply/map/transform no Pandas e quando evitar apply por performance.",
                "difficulty": 4,
                "tags": [],
                "expected": "apply executa fun√ß√£o Python linha a linha (lento). map aplica em Series. transform retorna mesma forma do grupo.\nEvite apply em grandes volumes; prefira opera√ß√µes vetorizadas, .str, .dt, numpy ufuncs, ou use numba/cython quando necess√°rio."
              },
              {
                "id": "ch7_q11",
                "type": [
                  "pandas",
                  "pivot"
                ],
                "prompt": "O que √© EDA (Exploratory Data Analysis) e quais 8 checagens m√≠nimas voc√™ faria antes de modelar?",
                "difficulty": 3,
                "tags": [],
                "expected": "Checagens: tamanho e dtypes; % missing por coluna; estat√≠sticas (describe); distribui√ß√£o/assimetria; outliers; cardinalidade de categ√≥ricas; correla√ß√£o entre num√©ricas; vazamento/colunas p√≥s-evento; duplicatas; balanceamento do target."
              },
              {
                "id": "ch7_q12",
                "type": [
                  "pandas",
                  "lambda"
                ],
                "prompt": "Como calcular e interpretar correla√ß√£o? Diferencie Pearson e Spearman e quando preferir cada um.",
                "difficulty": 4,
                "tags": [],
                "expected": "Pearson mede rela√ß√£o linear (sens√≠vel a outliers). Spearman usa ranks, captura monotonicidade e √© mais robusto a n√£o linearidades.\nUse Spearman quando h√° rela√ß√£o monot√¥nica n√£o linear ou dados com outliers/ordinais; sempre interprete correla√ß√£o como associa√ß√£o, n√£o causalidade."
              },
              {
                "id": "ch7_q13",
                "type": [
                  "pandas",
                  "agrega√ß√£o"
                ],
                "prompt": "Por que correla√ß√£o alta entre features √© um problema para alguns modelos? D√™ um exemplo pr√°tico (multicolinearidade).",
                "difficulty": 4,
                "tags": [],
                "expected": "Em regress√µes lineares, multicolinearidade torna coeficientes inst√°veis e dif√≠cil interpretar impacto individual.\nEx.: ‚Äúidade‚Äù e ‚Äútempo de carteira‚Äù altamente correlacionados; o modelo pode alternar sinais/magnitudes. Solu√ß√µes: remover, combinar, PCA ou regularizar (Ridge/Lasso)."
              },
              {
                "id": "ch7_q14",
                "type": [
                  "pandas",
                  "gr√°ficos"
                ],
                "prompt": "Explique SciPy em uma frase e cite 4 tipos de tarefas em que ele √© especialmente √∫til.",
                "difficulty": 3,
                "tags": [],
                "expected": "SciPy complementa NumPy com algoritmos cient√≠ficos: estat√≠stica (testes, distribui√ß√µes), otimiza√ß√£o, √°lgebra linear avan√ßada, sinais e interpola√ß√£o.\n√ötil para testes de hip√≥tese, ajuste de curvas, resolu√ß√£o de sistemas e an√°lise de sinais/tempo."
              },
              {
                "id": "ch7_q15",
                "type": [
                  "visualiza√ß√£o"
                ],
                "prompt": "O que √© scikit-learn e qual √© o padr√£o 'Estimator API'? Explique fit, transform, predict e score.",
                "difficulty": 3,
                "tags": [],
                "expected": "scikit-learn √© a biblioteca padr√£o de ML cl√°ssica. Estimators seguem API consistente.\nfit aprende par√¢metros; transform gera features; predict prev√™; score calcula m√©trica default. Esse padr√£o facilita trocar modelos e montar pipelines."
              },
              {
                "id": "ch7_q16",
                "type": [
                  "visualiza√ß√£o",
                  "scatter"
                ],
                "prompt": "Mostre por que usar Pipeline do scikit-learn √© melhor do que fazer pr√©-processamento manual fora do treino.",
                "difficulty": 4,
                "tags": [],
                "expected": "Pipeline encapsula etapas e evita leakage: scaler/encoder aprende s√≥ no treino e aplica igual no teste.\nAl√©m disso, facilita grid search com valida√ß√£o correta, serializa√ß√£o e deploy. Pr√©-processar ‚Äúfora‚Äù tende a misturar dados e inflar m√©tricas."
              },
              {
                "id": "ch7_q17",
                "type": [
                  "visualiza√ß√£o",
                  "barras"
                ],
                "prompt": "Explique ColumnTransformer e descreva um pipeline t√≠pico para dados com colunas num√©ricas e categ√≥ricas.",
                "difficulty": 4,
                "tags": [],
                "expected": "ColumnTransformer aplica transforma√ß√µes por subconjunto de colunas.\nT√≠pico: num√©ricas ‚Üí StandardScaler; categ√≥ricas ‚Üí OneHotEncoder(handle_unknown='ignore'); depois modelo (LogReg/SVM/√Årvore). Tudo dentro de Pipeline para CV segura."
              },
              {
                "id": "ch7_q18",
                "type": [
                  "visualiza√ß√£o",
                  "histograma"
                ],
                "prompt": "Como versionar e salvar artefatos de ML (modelos, encoders, colunas)? O que pode dar errado se voc√™ salvar s√≥ o modelo?",
                "difficulty": 4,
                "tags": [],
                "expected": "Salve pipeline inteiro (joblib) + lista de colunas + vers√£o de libs + metadados do treino.\nSe salvar s√≥ o modelo, voc√™ perde scaler/encoder e ordem de colunas; em produ√ß√£o, o input muda e as previs√µes ficam incorretas sem erro √≥bvio."
              },
              {
                "id": "ch7_q19",
                "type": [
                  "pandas",
                  "io"
                ],
                "prompt": "Explique por que notebooks s√£o √≥timos para explora√ß√£o, mas perigosos para produ√ß√£o. Cite boas pr√°ticas para reduzir riscos.",
                "difficulty": 3,
                "tags": [],
                "expected": "Notebooks t√™m estado oculto e execu√ß√£o fora de ordem. Para reduzir riscos: reiniciar e rodar ‚Äúall‚Äù; modularizar em fun√ß√µes; usar seeds; registrar vers√µes; exportar pipeline para m√≥dulo; testes m√≠nimos e revis√£o de dados/artefatos."
              },
              {
                "id": "ch7_q20",
                "type": [
                  "eda"
                ],
                "prompt": "Quais s√£o as vantagens e desvantagens de trabalhar com dados em mem√≥ria (Pandas) vs em banco/engine (SQL/Spark)?",
                "difficulty": 4,
                "tags": [],
                "expected": "Em mem√≥ria: r√°pido para explorar, simples, mas limitado por RAM e pode ser lento em joins grandes.\nSQL/Spark: escala e otimiza, mas exige infraestrutura e pode reduzir interatividade. Estrat√©gia: filtrar/aggregar no banco e trazer amostra/feature set para Pandas."
              },
              {
                "id": "ch7_q21",
                "type": [
                  "profiling"
                ],
                "prompt": "Explique o conceito de 'lazy evaluation' (em engines como Spark) e por que isso muda como voc√™ depura um pipeline.",
                "difficulty": 4,
                "tags": [],
                "expected": "Lazy evaluation adia execu√ß√£o at√© uma a√ß√£o. Isso melhora otimiza√ß√£o, mas erros s√≥ aparecem na hora de executar.\nDepura√ß√£o exige validar schemas, usar a√ß√µes pequenas (limit/count), cachear pontos cr√≠ticos e entender plano de execu√ß√£o."
              },
              {
                "id": "ch7_q22",
                "type": [
                  "profiling"
                ],
                "prompt": "Como lidar com datasets muito grandes no Pandas sem travar a m√°quina? Liste estrat√©gias pr√°ticas.",
                "difficulty": 4,
                "tags": [],
                "expected": "Use: leitura em chunks; tipos menores (int32, category); filtrar colunas; amostragem estratificada; agrega√ß√µes pr√©vias; parquet/feather; evitar c√≥pias; usar Dask/Polars/Spark quando necess√°rio."
              },
              {
                "id": "ch7_q23",
                "type": [
                  "correla√ß√£o"
                ],
                "prompt": "Explique 'categorical dtype' no Pandas. Quando usar e que ganho esperar?",
                "difficulty": 3,
                "tags": [],
                "expected": "Categorical armazena dicion√°rio de categorias + c√≥digos, economizando mem√≥ria e acelerando opera√ß√µes como groupby em colunas repetitivas.\nUse para colunas com baixa cardinalidade relativa (estado, sexo, tipo_produto) e muitas repeti√ß√µes."
              },
              {
                "id": "ch7_q24",
                "type": [
                  "numpy"
                ],
                "prompt": "Como detectar e remover duplicatas corretamente? Por que remover duplicatas sem crit√©rio pode ser perigoso?",
                "difficulty": 4,
                "tags": [],
                "expected": "Use duplicated/subset para checar chaves; decida regra (manter primeiro/√∫ltimo) e preserve informa√ß√£o quando necess√°rio (agregar).\nPerigo: duplicatas podem representar eventos reais (compras repetidas). Remover sem entender pode distorcer m√©tricas e labels."
              },
              {
                "id": "ch7_q25",
                "type": [
                  "numpy",
                  "reshape"
                ],
                "prompt": "Explique 'data types' e convers√µes no Pandas (astype). D√™ um exemplo de bug silencioso por dtype errado.",
                "difficulty": 3,
                "tags": [],
                "expected": "dtype define como valores s√£o interpretados. Ex.: '00123' lido como int vira 123 e perde zeros; datas lidas como string quebram ordena√ß√£o temporal.\nSempre valide com df.dtypes, parse_dates e convers√µes expl√≠citas."
              },
              {
                "id": "ch7_q26",
                "type": [
                  "numpy",
                  "performance"
                ],
                "prompt": "O que √© 'feature leakage' em dados tabulares e como a pr√≥pria EDA pode revelar esse problema?",
                "difficulty": 4,
                "tags": [],
                "expected": "Leakage aparece quando uma coluna ‚Äúantecipa‚Äù o target (status_final, valor_pago).\nNa EDA, sinais: correla√ß√£o/performance absurdas, coluna com valores que s√≥ existem ap√≥s o evento, e import√¢ncia dominada. Inspecione dicion√°rio de dados e gere split temporal/grupo para confirmar."
              },
              {
                "id": "ch7_q27",
                "type": [
                  "sklearn"
                ],
                "prompt": "Explique diferen√ßas entre StandardScaler, OneHotEncoder e OrdinalEncoder. Quando OrdinalEncoder pode prejudicar o modelo?",
                "difficulty": 4,
                "tags": [],
                "expected": "StandardScaler ajusta escala num√©rica. OneHot cria colunas bin√°rias sem ordem. OrdinalEncoder mapeia categorias para n√∫meros com ordem artificial.\nPode prejudicar quando n√£o existe ordena√ß√£o real (cores, cidades), pois cria dist√¢ncia ‚Äúfalsa‚Äù; prefira OneHot ou embeddings."
              },
              {
                "id": "ch7_q28",
                "type": [
                  "ecossistema"
                ],
                "prompt": "Como escolher uma m√©trica de avalia√ß√£o adequada? D√™ um exemplo em classifica√ß√£o desbalanceada e um em regress√£o.",
                "difficulty": 4,
                "tags": [],
                "expected": "Escolha pela decis√£o/custo. Desbalanceada: priorize PR-AUC, F1, recall@precision e threshold; evite s√≥ accuracy. Regress√£o: MAE (robusto), RMSE (penaliza grandes erros), R¬≤ (explica√ß√£o relativa).\nDefina antes de treinar para evitar ‚Äúp-hacking‚Äù."
              },
              {
                "id": "ch7_q29",
                "type": [
                  "pipeline",
                  "missing"
                ],
                "prompt": "O que √© uma 'fun√ß√£o de perda' e como ela se relaciona com a m√©trica que voc√™ reporta?",
                "difficulty": 4,
                "tags": [],
                "expected": "Perda √© o que o algoritmo otimiza (ex.: log-loss, MSE). M√©trica √© o que voc√™ comunica/decide (F1, AUC, MAE).\nElas podem ser diferentes; por isso voc√™ ajusta threshold/tuning para otimizar a m√©trica de neg√≥cio, mesmo se o treino otimiza outra."
              },
              {
                "id": "ch7_q30",
                "type": [
                  "pipeline"
                ],
                "prompt": "Explique em que situa√ß√µes voc√™ usaria statsmodels em vez de scikit-learn.",
                "difficulty": 4,
                "tags": [],
                "expected": "statsmodels √© forte em infer√™ncia estat√≠stica: testes, intervalos, p‚Äëvalues, diagn√≥sticos e interpreta√ß√£o formal de regress√µes.\nUse quando o objetivo √© explicar rela√ß√£o entre vari√°veis, hip√≥teses e signific√¢ncia; scikit-learn √© mais focado em predi√ß√£o e pipelines."
              },
              {
                "id": "ch7_q31",
                "type": [
                  "numpy",
                  "arrays"
                ],
                "prompt": "Qual a diferen√ßa entre 'train_test_split' e 'StratifiedKFold'? Quando estratificar √© essencial?",
                "difficulty": 3,
                "tags": [],
                "expected": "train_test_split cria uma √∫nica parti√ß√£o; StratifiedKFold cria v√°rias dobras mantendo propor√ß√£o de classes.\nEstratificar √© essencial em classes desbalanceadas para evitar dobras sem positivos/negativos, que tornam m√©tricas inst√°veis e tuning enganoso."
              },
              {
                "id": "ch7_q32",
                "type": [
                  "numpy",
                  "broadcast"
                ],
                "prompt": "Explique o que √© 'random_state' em scikit-learn e por que voc√™ deve registrar esse valor em experimentos.",
                "difficulty": 3,
                "tags": [],
                "expected": "random_state fixa aleatoriedade (split, inicializa√ß√£o, amostragem). Sem isso, resultados variam e voc√™ n√£o sabe se a melhoria foi real ou sorte.\nRegistrar permite reproduzir o experimento e comparar modelos com justi√ßa."
              },
              {
                "id": "ch7_q33",
                "type": [
                  "numpy",
                  "performance"
                ],
                "prompt": "O que √© um 'dicion√°rio de dados' e por que ele evita erros caros em ML?",
                "difficulty": 3,
                "tags": [],
                "expected": "√â documenta√ß√£o de colunas: significado, unidade, faixa v√°lida, momento de captura e regras de neg√≥cio.\nEle ajuda a detectar leakage, entender missing, escolher encoding correto e evitar usar campos ilegais (PII, p√≥s-evento) ‚Äî economiza tempo e evita conclus√µes erradas."
              },
              {
                "id": "ch7_q34",
                "type": [
                  "pandas",
                  "groupby"
                ],
                "prompt": "Explique a diferen√ßa entre 'batch' e 'stream' na ingest√£o de dados. Como isso afeta o design de features?",
                "difficulty": 5,
                "tags": [],
                "expected": "Batch processa em lotes (di√°rio, semanal). Stream chega em tempo real. Em stream, features precisam ser comput√°veis online (janelas, contagens incrementais) e consistentes com o treino.\nA diverg√™ncia treino vs produ√ß√£o √© um bug cl√°ssico (training-serving skew)."
              },
              {
                "id": "ch7_q35",
                "type": [
                  "pandas",
                  "merge"
                ],
                "prompt": "Descreva uma checklist de qualidade de dados (Data Quality) que voc√™ aplicaria antes de treinar.",
                "difficulty": 4,
                "tags": [],
                "expected": "Checar: esquema e dtypes; ranges e valores inv√°lidos; duplicatas; missing por coluna/segmento; consist√™ncia de chaves; outliers; drift b√°sico; balanceamento do target; integridade referencial em joins.\nAutomatize essas checagens para evitar retrabalho."
              },
              {
                "id": "ch7_q36",
                "type": [
                  "pandas",
                  "categorical"
                ],
                "prompt": "Explique como identificar outliers e por que 'remover outliers' sem crit√©rio pode piorar o modelo.",
                "difficulty": 4,
                "tags": [],
                "expected": "Outliers podem ser erros de medi√ß√£o ou casos raros importantes. Identifique via boxplot, z‚Äëscore, IQR, isola√ß√£o por densidade e inspe√ß√£o de dom√≠nio.\nRemover sem crit√©rio pode apagar a classe rara que voc√™ quer detectar; prefira robustez (MAE, transforma√ß√µes, modelos robustos) ou regras de dom√≠nio."
              },
              {
                "id": "ch7_q37",
                "type": [
                  "sklearn",
                  "pipeline"
                ],
                "prompt": "Compare seaborn e matplotlib em uma frase e diga quando voc√™ usaria cada um (mesmo que o curso foque em matplotlib).",
                "difficulty": 3,
                "tags": [],
                "expected": "Matplotlib √© a base flex√≠vel e low-level; Seaborn oferece padr√µes estat√≠sticos e est√©tica pronta para EDA.\nUse Seaborn para EDA r√°pida (distribui√ß√µes, pairplot) e Matplotlib para customiza√ß√£o fina, gr√°ficos de produ√ß√£o e controle total."
              },
              {
                "id": "ch7_q38",
                "type": [
                  "sklearn",
                  "preprocess"
                ],
                "prompt": "Explique o que √© 'serializa√ß√£o' (pickle/joblib) e cite um risco de seguran√ßa/compatibilidade ao carregar modelos serializados.",
                "difficulty": 5,
                "tags": [],
                "expected": "Serializar salva objetos Python em bytes. joblib √© comum para modelos sklearn.\nRiscos: incompatibilidade de vers√µes (objeto muda) e seguran√ßa (pickle pode executar c√≥digo ao carregar). S√≥ carregue artefatos confi√°veis e versionados."
              },
              {
                "id": "ch7_q39",
                "type": [
                  "ambiente",
                  "jupyter"
                ],
                "prompt": "Descreva como voc√™ estruturaria pastas de um projeto de ML para manter notebooks, dados, c√≥digo e artefatos organizados.",
                "difficulty": 3,
                "tags": [],
                "expected": "Estruture: /data (raw, processed), /notebooks, /src (features, models, utils), /reports (figuras), /models (pipelines), /configs, /tests.\nIsso facilita reuso, revis√£o e deploy, e impede misturar dados brutos com resultados e modelos."
              },
              {
                "id": "ch7_q40",
                "type": [
                  "reprodutibilidade",
                  "pip"
                ],
                "prompt": "Explique por que testes automatizados (mesmo simples) s√£o √∫teis em pipelines de dados. D√™ 3 exemplos de testes.",
                "difficulty": 4,
                "tags": [],
                "expected": "Pipelines quebram silenciosamente. Testes: (1) esquema: colunas/dtypes esperados; (2) ranges: idade>=0, taxa<=1; (3) integridade: %missing < limite; (4) split sem vazamento (grupos).\nEles evitam modelos treinados em dados ‚Äúcorrompidos‚Äù."
              }
            ]
          },
          {
            "chapter": 8,
            "id": "matplotlib",
            "title": "A Biblioteca Gr√°fica Matplotlib",
            "keyTopics": [
              "PyPlot",
              "linhas",
              "dispers√£o",
              "op√ß√µes do Matplotlib (t√≠tulos, r√≥tulos, grid, legend, estilos)"
            ],
            "questions": [
              {
                "id": "ch8_q01",
                "type": [
                  "matplotlib"
                ],
                "prompt": "Explique a diferen√ßa entre a API 'pyplot' e a abordagem orientada a objetos (Figure/Axes) no Matplotlib. Por que a OO costuma ser melhor para projetos maiores?",
                "difficulty": 3,
                "tags": [],
                "expected": "pyplot √© um estado global (r√°pido para scripts). OO cria Figure e Axes explicitamente, facilitando m√∫ltiplos gr√°ficos, reuso e controle fino.\nEm projetos maiores, OO evita efeitos colaterais, melhora legibilidade e permite compor layouts complexos com previsibilidade."
              },
              {
                "id": "ch8_q02",
                "type": [
                  "matplotlib",
                  "pyplot"
                ],
                "prompt": "O que s√£o Figure e Axes? Descreva como isso se relaciona com subplots.",
                "difficulty": 2,
                "tags": [],
                "expected": "Figure √© o ‚Äúcanvas‚Äù geral; Axes √© onde os dados s√£o desenhados (eixos, ticks, labels).\nSubplots cria v√°rios Axes dentro de uma Figure, permitindo comparar gr√°ficos lado a lado mantendo estilos e escalas consistentes."
              },
              {
                "id": "ch8_q03",
                "type": [
                  "matplotlib",
                  "linhas"
                ],
                "prompt": "Crie um gr√°fico de linha conceitualmente: quais elementos voc√™ ajusta para torn√°-lo leg√≠vel (t√≠tulo, eixos, limites, grade, legenda)?",
                "difficulty": 3,
                "tags": [],
                "expected": "Ajuste: t√≠tulo que responda a uma pergunta; r√≥tulos e unidades nos eixos; limites (xlim/ylim) evitando zoom enganoso; grid leve para leitura; legenda clara; tamanho de fonte e espa√ßamento para n√£o cortar textos."
              },
              {
                "id": "ch8_q04",
                "type": [
                  "visualiza√ß√£o"
                ],
                "prompt": "Explique quando usar scatter vs line plot. O que um scatter pode revelar que uma linha pode esconder?",
                "difficulty": 3,
                "tags": [],
                "expected": "Line plot sugere continuidade/ordem; scatter revela densidade, clusters, outliers e n√£o linearidades.\nScatter mostra rela√ß√£o entre duas vari√°veis sem impor conex√£o; pode evidenciar heteroscedasticidade e padr√µes por grupos."
              },
              {
                "id": "ch8_q05",
                "type": [
                  "visualiza√ß√£o",
                  "scatter"
                ],
                "prompt": "Explique como visualizar distribui√ß√£o de uma vari√°vel: histograma, KDE e boxplot. O que cada um destaca?",
                "difficulty": 3,
                "tags": [],
                "expected": "Histograma mostra contagens por bins; KDE suaviza a densidade; boxplot resume mediana, quartis e outliers.\nUse hist/KDE para formato (assimetria, multimodal) e boxplot para comparar grupos rapidamente."
              },
              {
                "id": "ch8_q06",
                "type": [
                  "matplotlib",
                  "customiza√ß√£o"
                ],
                "prompt": "O que √© um gr√°fico de barras? Cite 2 erros comuns ao usar barras e como evitar.",
                "difficulty": 4,
                "tags": [],
                "expected": "Barras comparam categorias. Erros: (1) eixo y n√£o come√ßar em zero, distorcendo compara√ß√£o; (2) categorias em ordem aleat√≥ria, dificultando leitura.\nEvite com baseline em zero (quando apropriado), ordene por valor e rotule bem."
              },
              {
                "id": "ch8_q07",
                "type": [
                  "comunica√ß√£o"
                ],
                "prompt": "Explique como salvar figuras com qualidade (dpi, bbox_inches, formatos). Quando preferir PNG vs SVG/PDF?",
                "difficulty": 3,
                "tags": [],
                "expected": "Use savefig com dpi adequado (ex.: 150‚Äì300), bbox_inches='tight' para n√£o cortar r√≥tulos.\nPNG √© bom para raster e web; SVG/PDF para vetorial (publica√ß√£o, impress√£o) e escalabilidade sem perda."
              },
              {
                "id": "ch8_q08",
                "type": [
                  "matplotlib"
                ],
                "prompt": "Como lidar com muitos pontos (overplotting) em scatter? Liste 4 estrat√©gias.",
                "difficulty": 4,
                "tags": [],
                "expected": "Estrat√©gias: reduzir alpha (transpar√™ncia), amostrar dados, usar hexbin/2D hist, agregar (binning), usar jitter para categorias, e destacar outliers/centroides.\nIsso melhora interpreta√ß√£o sem mentir sobre densidade."
              },
              {
                "id": "ch8_q09",
                "type": [
                  "visualiza√ß√£o",
                  "√©tica"
                ],
                "prompt": "Explique o que √© 'limite de eixo' e por que escolher limites manualmente pode ser perigoso.",
                "difficulty": 4,
                "tags": [],
                "expected": "Limites controlam o ‚Äúzoom‚Äù. Ajustar manualmente pode esconder outliers ou exagerar diferen√ßas.\nBoa pr√°tica: justificar limites (dom√≠nio, unidades), mostrar outliers separadamente e evitar cortar dados sem avisar."
              },
              {
                "id": "ch8_q10",
                "type": [
                  "comunica√ß√£o"
                ],
                "prompt": "O que √© anota√ß√£o (annotate) e quando ela melhora um gr√°fico? D√™ um exemplo de uso em ML/EDA.",
                "difficulty": 3,
                "tags": [],
                "expected": "Anota√ß√µes destacam eventos/pontos importantes (pico, anomalia, mudan√ßa de regime).\nEm ML: marcar erro m√°ximo, ponto de inflex√£o, fronteira de decis√£o, ou per√≠odo de drift em s√©rie temporal."
              },
              {
                "id": "ch8_q11",
                "type": [
                  "matplotlib",
                  "figure_axes"
                ],
                "prompt": "Explique como comparar v√°rias s√©ries no mesmo gr√°fico sem virar 'salada visual'.",
                "difficulty": 4,
                "tags": [],
                "expected": "Limite n√∫mero de s√©ries, use legenda clara, diferencie com estilos (linha/marker), normalize quando necess√°rio, e prefira facetar (subplots) quando h√° muitas curvas.\nDestaque a s√©rie principal e reduza ru√≠do com grid leve e r√≥tulos diretos."
              },
              {
                "id": "ch8_q12",
                "type": [
                  "matplotlib",
                  "subplots"
                ],
                "prompt": "Como construir subplots (layout) e garantir que r√≥tulos n√£o se sobreponham?",
                "difficulty": 3,
                "tags": [],
                "expected": "Use subplots(nrows,ncols) e ajuste layout com tight_layout() ou constrained_layout=True.\nControle size da Figure, rotacione ticks quando necess√°rio e padronize escalas para compara√ß√µes justas."
              },
              {
                "id": "ch8_q13",
                "type": [
                  "matplotlib",
                  "hist"
                ],
                "prompt": "Explique a diferen√ßa entre escala linear e logar√≠tmica. Quando usar escala log em EDA?",
                "difficulty": 3,
                "tags": [],
                "expected": "Escala log comprime valores grandes e expande pequenos, √∫til para dados com cauda longa (renda, acessos, bytes).\nUse log para visualizar multiplica√ß√µes/ordens de grandeza e para rela√ß√µes aproximadamente exponenciais."
              },
              {
                "id": "ch8_q14",
                "type": [
                  "matplotlib",
                  "bar"
                ],
                "prompt": "Como plotar s√©ries temporais corretamente (datas no eixo x)? Cite 3 cuidados.",
                "difficulty": 4,
                "tags": [],
                "expected": "Cuidados: converter para datetime, ordenar por tempo, usar formata√ß√£o de datas (AutoDateLocator/Formatter), e evitar muitos ticks.\nTamb√©m: sinalizar lacunas, usar m√©dias m√≥veis para tend√™ncia e separar sazonalidade quando necess√°rio."
              },
              {
                "id": "ch8_q15",
                "type": [
                  "matplotlib",
                  "savefig"
                ],
                "prompt": "Explique 'colormap' em gr√°ficos de calor (heatmap). Qual armadilha comum em heatmaps de correla√ß√£o?",
                "difficulty": 4,
                "tags": [],
                "expected": "Colormap mapeia valores para cores. Em correla√ß√£o, armadilha: interpretar correla√ß√£o como causalidade e ignorar tamanho de amostra.\nTamb√©m √© comum n√£o ordenar vari√°veis, perdendo blocos de correla√ß√£o; reordene ou use clustering para revelar estrutura."
              },
              {
                "id": "ch8_q16",
                "type": [
                  "matplotlib",
                  "annotations"
                ],
                "prompt": "Como voc√™ desenharia um gr√°fico para comunicar resultado de um modelo (ex.: compara√ß√£o de m√©tricas)? O que n√£o pode faltar?",
                "difficulty": 5,
                "tags": [],
                "expected": "Inclua: m√©trica, baseline, intervalo/vari√¢ncia (CV), tamanho do dataset e protocolo de valida√ß√£o.\nMostre compara√ß√£o justa (mesmas dobras) e destaque trade-offs (ex.: precis√£o vs recall). Sem contexto, gr√°fico vira ‚Äúmarketing‚Äù."
              },
              {
                "id": "ch8_q17",
                "type": [
                  "matplotlib",
                  "style"
                ],
                "prompt": "Explique o que √© 'aspect ratio' e por que ele pode distorcer percep√ß√µes em gr√°ficos de dispers√£o.",
                "difficulty": 4,
                "tags": [],
                "expected": "Aspect ratio √© a propor√ß√£o entre escalas x e y. Se distorcido, pode ‚Äúachatar‚Äù ou ‚Äúalongar‚Äù tend√™ncias, mudando interpreta√ß√£o da inclina√ß√£o/correla√ß√£o.\nPara rela√ß√µes geom√©tricas (dist√¢ncias), use aspect='equal' quando fizer sentido."
              },
              {
                "id": "ch8_q18",
                "type": [
                  "matplotlib",
                  "scatter"
                ],
                "prompt": "Quando voc√™ preferiria uma tabela em vez de um gr√°fico? D√™ crit√©rios.",
                "difficulty": 3,
                "tags": [],
                "expected": "Tabela √© melhor para valores exatos, poucas linhas/colunas e compara√ß√£o precisa.\nGr√°fico √© melhor para padr√µes, tend√™ncias e distribui√ß√µes. Se o leitor precisa ‚Äúler n√∫meros‚Äù, tabela vence; se precisa ‚Äúver padr√µes‚Äù, gr√°fico vence."
              },
              {
                "id": "ch8_q19",
                "type": [
                  "matplotlib",
                  "grid_legend"
                ],
                "prompt": "Explique boas pr√°ticas para t√≠tulos e legendas: como transformar o t√≠tulo em uma frase que responde a uma pergunta.",
                "difficulty": 3,
                "tags": [],
                "expected": "Evite t√≠tulos gen√©ricos (‚ÄúGr√°fico 1‚Äù). Use t√≠tulo que responda: ‚ÄúVendas caem ap√≥s julho?‚Äù.\nLegenda deve explicar s√©ries sem jarg√£o, e unidades devem estar nos eixos. Isso torna o gr√°fico autoexplicativo fora do contexto do notebook."
              },
              {
                "id": "ch8_q20",
                "type": [
                  "matplotlib",
                  "ticks"
                ],
                "prompt": "Descreva um checklist r√°pido para revisar um gr√°fico antes de publicar.",
                "difficulty": 4,
                "tags": [],
                "expected": "Checklist: (1) pergunta clara; (2) eixos com r√≥tulos/unidades; (3) escala apropriada (zero/log); (4) legenda e cores distingu√≠veis; (5) sem overplotting; (6) fonte leg√≠vel; (7) n√£o cortar textos; (8) salvar em formato adequado; (9) fonte dos dados/protocolo indicado."
              }
            ]
          },
          {
            "chapter": 9,
            "id": "regressao_linear_simples",
            "title": "Regress√£o Linear Simples",
            "keyTopics": [
              "carga bibliotecas/dados",
              "vari√°veis dependente/independente",
              "split + cross-validation",
              "treino",
              "predi√ß√£o",
              "visualiza√ß√£o resultados"
            ],
            "questions": [
              {
                "id": "ch9_q01",
                "type": [
                  "regress√£o_linear"
                ],
                "prompt": "Explique a hip√≥tese de linearidade na Regress√£o Linear Simples. Como voc√™ verificaria se ela √© razo√°vel em um dataset real?",
                "difficulty": 3,
                "tags": [],
                "expected": "A hip√≥tese √© que y varia aproximadamente de forma linear com x. Verifique com scatter plot, ajuste visual, e res√≠duos vs x.\nSe houver curva, tente transforma√ß√µes (log, raiz), termos polinomiais ou outro modelo (√°rvore, SVR) e compare por valida√ß√£o cruzada."
              },
              {
                "id": "ch9_q02",
                "type": [
                  "regress√£o"
                ],
                "prompt": "Interprete o coeficiente angular (Œ≤1) e o intercepto (Œ≤0) em linguagem de neg√≥cio e com unidades.",
                "difficulty": 2,
                "tags": [],
                "expected": "Œ≤1 √© a varia√ß√£o m√©dia esperada em y para +1 unidade em x. Œ≤0 √© o valor previsto quando x=0 (pode n√£o ter sentido fora do dom√≠nio).\nSempre cite unidades: 'a cada 1 real em marketing, vendas sobem ~Œ≤1 reais', por exemplo."
              },
              {
                "id": "ch9_q03",
                "type": [
                  "valida√ß√£o"
                ],
                "prompt": "Por que separar treino e teste √© necess√°rio em regress√£o? O que significa 'generalizar' neste contexto?",
                "difficulty": 3,
                "tags": [],
                "expected": "Sem teste voc√™ mede ajuste ao passado, n√£o a capacidade de prever novos dados. Generalizar √© manter erro baixo em dados n√£o vistos, semelhantes aos futuros.\nIsso evita conclus√µes otimistas e exp√µe overfitting e problemas de leakage."
              },
              {
                "id": "ch9_q04",
                "type": [
                  "cross_validation"
                ],
                "prompt": "Compare MAE, MSE e RMSE. Em quais cen√°rios RMSE √© prefer√≠vel e em quais MAE √© mais robusto?",
                "difficulty": 3,
                "tags": [],
                "expected": "MAE penaliza linearmente e √© mais robusto a outliers. MSE/RMSE penalizam erros grandes mais forte (quadr√°tico).\nUse RMSE quando erros grandes s√£o muito caros; use MAE quando h√° ru√≠do e valores extremos que voc√™ n√£o quer deixar dominar a m√©trica."
              },
              {
                "id": "ch9_q05",
                "type": [
                  "pipeline"
                ],
                "prompt": "O que √© R¬≤? Por que um R¬≤ alto n√£o garante um bom modelo preditivo?",
                "difficulty": 4,
                "tags": [],
                "expected": "R¬≤ √© a fra√ß√£o da vari√¢ncia de y explicada pelo modelo em rela√ß√£o ao baseline (m√©dia). Pode ficar alto por vazamento, por dom√≠nio restrito ou por correla√ß√µes esp√∫rias.\nN√£o garante bom erro absoluto nem bom comportamento em novos dados; sempre valide e analise res√≠duos."
              },
              {
                "id": "ch9_q06",
                "type": [
                  "predi√ß√£o",
                  "avalia√ß√£o"
                ],
                "prompt": "Explique an√°lise de res√≠duos. Quais padr√µes indicam que o modelo linear est√° errado ou incompleto?",
                "difficulty": 4,
                "tags": [],
                "expected": "Res√≠duos devem parecer ru√≠do sem padr√£o. Padr√µes comuns: curva (n√£o linearidade), funil (heteroscedasticidade), autocorrela√ß√£o temporal, clusters por grupos (feature faltante) e outliers influentes.\nUse res√≠duos vs predito, res√≠duos vs x e, quando fizer sentido, QQ-plot."
              },
              {
                "id": "ch9_q07",
                "type": [
                  "visualiza√ß√£o"
                ],
                "prompt": "O que √© heteroscedasticidade e por que ela importa? Cite formas pr√°ticas de lidar com isso.",
                "difficulty": 4,
                "tags": [],
                "expected": "Heteroscedasticidade √© quando a vari√¢ncia dos erros muda com x ou com o valor previsto. Isso causa erros maiores em certas faixas.\nLide com transforma√ß√µes (ex.: log y), modelos robustos, pondera√ß√£o (WLS) ou segmenta√ß√£o; valide por faixa e por CV."
              },
              {
                "id": "ch9_q08",
                "type": [
                  "diagn√≥stico"
                ],
                "prompt": "Diferencie outlier de ponto influente. Como detectar e como decidir se remove ou mant√©m?",
                "difficulty": 4,
                "tags": [],
                "expected": "Outlier √© um valor extremo; ponto influente altera muito a reta ajustada. Detecte com res√≠duos padronizados, leverage e Cook's distance.\nRemova apenas se for erro de dado; se for um caso real, trate com robustez (transforma√ß√£o, modelos robustos) e explique o impacto."
              },
              {
                "id": "ch9_q09",
                "type": [
                  "estat√≠stica"
                ],
                "prompt": "Padronizar (StandardScaler) muda as previs√µes da Regress√£o Linear Simples? O que muda de fato?",
                "difficulty": 3,
                "tags": [],
                "expected": "Em OLS simples, padronizar x n√£o muda a qualidade das previs√µes (s√≥ reescala coeficientes e intercepto), mas melhora estabilidade num√©rica e facilita comparar efeitos.\nEm modelos com regulariza√ß√£o (Ridge/Lasso), padroniza√ß√£o √© essencial porque a penaliza√ß√£o depende da escala."
              },
              {
                "id": "ch9_q10",
                "type": [
                  "outliers"
                ],
                "prompt": "Descreva um pipeline m√≠nimo (em palavras) para regress√£o em scikit-learn, incluindo valida√ß√£o cruzada e teste final.",
                "difficulty": 3,
                "tags": [],
                "expected": "Defina m√©trica (MAE/RMSE), fa√ßa split (ou CV), encaixe pr√©-processamento se necess√°rio, treine LinearRegression, avalie em CV (m√©dia e desvio) e s√≥ no fim rode no teste.\nRegistre par√¢metros, seed e gr√°ficos de diagn√≥stico (real vs predito, res√≠duos)."
              },
              {
                "id": "ch9_q11",
                "type": [
                  "reprodutibilidade"
                ],
                "prompt": "Por que correla√ß√£o entre x e y n√£o implica causalidade, mesmo quando a regress√£o 'funciona'?",
                "difficulty": 4,
                "tags": [],
                "expected": "Regress√£o mede associa√ß√£o. Vari√°veis omitidas e confus√£o podem explicar a rela√ß√£o (ex.: desconto e churn).\nPara causalidade, precisa desenho experimental (A/B), controle de confounders e/ou m√©todos causais; caso contr√°rio, a√ß√µes baseadas no modelo podem falhar."
              },
              {
                "id": "ch9_q12",
                "type": [
                  "eda",
                  "avalia√ß√£o"
                ],
                "prompt": "Como escolher uma √∫nica vari√°vel independente para regress√£o simples (ou decidir que regress√£o simples √© inadequada)?",
                "difficulty": 3,
                "tags": [],
                "expected": "Escolha uma feature dispon√≠vel no momento da previs√£o, com significado de dom√≠nio e rela√ß√£o plaus√≠vel com o target. Verifique missing, outliers e estabilidade temporal.\nSe o erro ficar alto ou res√≠duos mostrarem padr√µes por grupos, provavelmente o problema exige m√∫ltiplas features ou outro modelo."
              },
              {
                "id": "ch9_q13",
                "type": [
                  "regressao_linear",
                  "equacao"
                ],
                "prompt": "Como checar se o modelo erra mais em certos segmentos (faixas, regi√µes, perfis)?",
                "difficulty": 4,
                "tags": [],
                "expected": "Calcule MAE/RMSE por bins (ex.: quintis) e por categorias (ex.: regi√£o). Visualize res√≠duos por segmento.\nSe houver disparidades, crie features adicionais, intera√ß√µes ou modelos segmentados e valide se melhora sem leakage."
              },
              {
                "id": "ch9_q14",
                "type": [
                  "regressao_linear",
                  "coeficientes"
                ],
                "prompt": "O que √© extrapola√ß√£o em regress√£o linear? D√™ um exemplo de risco e como mitigar.",
                "difficulty": 3,
                "tags": [],
                "expected": "Extrapolar √© prever para x fora do intervalo visto no treino. A reta pode produzir valores absurdos.\nMitigue limitando o dom√≠nio, coletando dados na faixa desejada, usando modelos com satura√ß√£o/regulariza√ß√£o e alertando o usu√°rio quando estiver fora do suporte."
              },
              {
                "id": "ch9_q15",
                "type": [
                  "regressao_linear",
                  "residuos"
                ],
                "prompt": "Explique sinais de overfitting em regress√£o simples e como identificar sensibilidade a poucos pontos.",
                "difficulty": 4,
                "tags": [],
                "expected": "Sinais: erro muito baixo no treino e alto no teste, e grande mudan√ßa nos coeficientes ao remover 1 ou 2 observa√ß√µes.\nUse valida√ß√£o cruzada, an√°lise de influ√™ncia (Cook) e teste de estabilidade (bootstrap) para confirmar."
              },
              {
                "id": "ch9_q16",
                "type": [
                  "m√©tricas",
                  "mse_mae"
                ],
                "prompt": "Como representar incerteza na previs√£o (intervalos) e por que isso pode ser mais √∫til que um √∫nico n√∫mero?",
                "difficulty": 5,
                "tags": [],
                "expected": "Intervalos comunicam risco: duas previs√µes iguais podem ter confiabilidade diferente. Use infer√™ncia (statsmodels) ou bootstrap para construir intervalos.\nEm decis√µes (estoque, cr√©dito), a faixa pode ser mais √∫til que o ponto central para planejar buffers e limites."
              },
              {
                "id": "ch9_q17",
                "type": [
                  "regressao_linear",
                  "assumptions"
                ],
                "prompt": "O que significa 'normalidade dos res√≠duos' e quando isso realmente importa (previs√£o vs infer√™ncia)?",
                "difficulty": 4,
                "tags": [],
                "expected": "Normalidade importa mais para infer√™ncia cl√°ssica (p-values, intervalos) do que para predi√ß√£o pura.\nMesmo assim, res√≠duos muito assim√©tricos podem indicar transforma√ß√µes necess√°rias, outliers ou distribui√ß√£o alvo inadequada."
              },
              {
                "id": "ch9_q18",
                "type": [
                  "regressao_linear",
                  "outliers"
                ],
                "prompt": "Estudo de caso: x=investimento em marketing, y=vendas. Quais perguntas voc√™ faria antes de concluir que marketing causa aumento em vendas?",
                "difficulty": 5,
                "tags": [],
                "expected": "Pergunte sobre sazonalidade, promo√ß√µes simult√¢neas, defasagem (lag), capacidade (teto), segmenta√ß√£o e canais. Cheque se investimento reage a vendas (causalidade reversa).\nIdeal: experimento A/B ou quasi-experimentos; no m√≠nimo, modelagem temporal com controles."
              },
              {
                "id": "ch9_q19",
                "type": [
                  "regressao_linear",
                  "r2"
                ],
                "prompt": "Quais resultados m√≠nimos voc√™ reportaria ao apresentar uma regress√£o linear simples a algu√©m de neg√≥cio?",
                "difficulty": 4,
                "tags": [],
                "expected": "Reporte: MAE/RMSE e R¬≤ em teste/CV, compara√ß√£o com baseline (m√©dia), gr√°fico real vs predito e res√≠duos vs predito.\nDescreva o protocolo de valida√ß√£o e os principais erros por segmento; sem isso, o resultado n√£o √© confi√°vel."
              },
              {
                "id": "ch9_q20",
                "type": [
                  "regressao_linear",
                  "correlation"
                ],
                "prompt": "Explique como voc√™ detectaria 'leakage' em um problema de regress√£o simples quando a m√©trica ficou alta demais.",
                "difficulty": 5,
                "tags": [],
                "expected": "Procure colunas p√≥s-evento e features que 'resumem' o target. Compare performance com split temporal e por grupo.\nCheque se o pr√©-processamento foi ajustado com dados do teste. Import√¢ncia dominada por uma √∫nica feature tamb√©m √© sinal cl√°ssico."
              }
            ]
          },
          {
            "chapter": 10,
            "id": "regressao_linear_multipla",
            "title": "Regress√£o Linear M√∫ltipla",
            "keyTopics": [
              "carga bibliotecas/dados",
              "vari√°veis dependente/independente",
              "split + cross-validation",
              "treino",
              "predi√ß√£o",
              "visualiza√ß√£o resultados",
              "m√∫ltiplas vari√°veis explicativas"
            ],
            "questions": [
              {
                "id": "ch10_q01",
                "type": [
                  "regress√£o_linear"
                ],
                "prompt": "Explique a ideia de Regress√£o Linear M√∫ltipla e como interpretar coeficientes 'mantendo as outras vari√°veis constantes'.",
                "difficulty": 3,
                "tags": [],
                "expected": "Na regress√£o m√∫ltipla, y √© explicada por v√°rias features: y = Œ≤0 + Œ≤1x1 + ... + Œ≤kxk. O coeficiente Œ≤i √© o efeito marginal de xi quando as outras vari√°veis ficam fixas.\nIsso exige cuidado: se features s√£o correlacionadas, 'manter constantes' pode ser irreal e os coeficientes ficam inst√°veis."
              },
              {
                "id": "ch10_q02",
                "type": [
                  "dados"
                ],
                "prompt": "O que √© multicolinearidade? Quais sintomas ela causa e como detectar (ex.: VIF)?",
                "difficulty": 4,
                "tags": [],
                "expected": "Multicolinearidade ocorre quando features s√£o altamente correlacionadas. Sintomas: coeficientes com sinais estranhos, grandes varia√ß√µes entre amostras e alta incerteza.\nDetecte por matriz de correla√ß√£o, VIF alto e instabilidade por bootstrap. Solu√ß√µes: remover/combinar features, PCA ou regulariza√ß√£o (Ridge/Lasso)."
              },
              {
                "id": "ch10_q03",
                "type": [
                  "correla√ß√£o",
                  "regress√£o"
                ],
                "prompt": "Como lidar com vari√°veis categ√≥ricas em regress√£o m√∫ltipla? Explique one-hot e a armadilha da 'dummy variable trap'.",
                "difficulty": 3,
                "tags": [],
                "expected": "Use OneHotEncoder para categorias sem ordem. A dummy trap √© incluir todas as dummies + intercepto, criando colinearidade perfeita.\nEm geral, o encoder remove uma categoria (drop='first') ou o modelo lida via regulariza√ß√£o; em sklearn, Pipeline/OneHot evita erros e mant√©m consist√™ncia."
              },
              {
                "id": "ch10_q04",
                "type": [
                  "cross_validation"
                ],
                "prompt": "Explique o papel do pr√©-processamento com ColumnTransformer em um dataset com num√©ricas, categ√≥ricas e datas.",
                "difficulty": 4,
                "tags": [],
                "expected": "Num√©ricas: imputa√ß√£o + StandardScaler; categ√≥ricas: imputa√ß√£o + OneHotEncoder(handle_unknown='ignore'); datas: extra√ß√£o de componentes (m√™s, dia da semana) ou features de janela.\nColumnTransformer aplica cada transforma√ß√£o no conjunto certo e permite CV sem leakage."
              },
              {
                "id": "ch10_q05",
                "type": [
                  "pipeline"
                ],
                "prompt": "Compare Ridge e Lasso. Quando Lasso pode ser √∫til e qual √© um risco ao interpret√°-lo?",
                "difficulty": 4,
                "tags": [],
                "expected": "Ridge (L2) encolhe coeficientes, lida bem com colinearidade e mant√©m todas as features. Lasso (L1) pode zerar coeficientes, funcionando como sele√ß√£o.\nRisco: em features correlacionadas, Lasso escolhe uma 'arbitrariamente'; interpreta√ß√£o deve considerar estabilidade e valida√ß√£o."
              },
              {
                "id": "ch10_q06",
                "type": [
                  "visualiza√ß√£o"
                ],
                "prompt": "Explique Elastic Net e por que ele pode ser uma boa escolha em regress√£o m√∫ltipla com muitas features correlacionadas.",
                "difficulty": 5,
                "tags": [],
                "expected": "Elastic Net combina L1 e L2, equilibrando sele√ß√£o (L1) e estabilidade (L2). Em alta correla√ß√£o, tende a selecionar grupos de features e reduzir instabilidade.\n√â comum em problemas com muitas vari√°veis (textos, one-hot grande) e ajuda generaliza√ß√£o."
              },
              {
                "id": "ch10_q07",
                "type": [
                  "avalia√ß√£o"
                ],
                "prompt": "Quais m√©tricas voc√™ usaria para avaliar regress√£o m√∫ltipla e por qu√™? Inclua pelo menos uma m√©trica 'em unidades do problema'.",
                "difficulty": 3,
                "tags": [],
                "expected": "Use MAE (em unidades reais, f√°cil de explicar), RMSE (penaliza erros grandes), e R¬≤/Adjusted R¬≤ (compara√ß√£o relativa).\nSempre reporte erro em unidades do neg√≥cio (ex.: reais, dias) e compare com baseline (m√©dia/mediana)."
              },
              {
                "id": "ch10_q08",
                "type": [
                  "exemplos"
                ],
                "prompt": "Explique 'Adjusted R¬≤' e por que ele √© relevante em regress√£o m√∫ltipla.",
                "difficulty": 4,
                "tags": [],
                "expected": "R¬≤ sempre aumenta (ou n√£o diminui) ao adicionar features, mesmo in√∫teis. Adjusted R¬≤ penaliza complexidade (n√∫mero de features) e pode diminuir quando a feature n√£o agrega.\n√â √∫til para comparar modelos com diferentes quantidades de vari√°veis, mas n√£o substitui valida√ß√£o em teste."
              },
              {
                "id": "ch10_q09",
                "type": [
                  "pr√©-processamento"
                ],
                "prompt": "Como voc√™ faria sele√ß√£o de features de forma correta (sem leakage) em um pipeline de regress√£o m√∫ltipla?",
                "difficulty": 5,
                "tags": [],
                "expected": "Fa√ßa sele√ß√£o dentro do Pipeline e dentro do loop de CV (ex.: SelectKBest, RFE, Lasso) para que a escolha use apenas treino em cada dobra.\nNunca selecione usando o dataset inteiro antes do split. Avalie estabilidade das features selecionadas e impacto no erro."
              },
              {
                "id": "ch10_q10",
                "type": [
                  "projeto"
                ],
                "prompt": "Explique intera√ß√µes entre vari√°veis (x1*x2). Quando faz sentido adicionar intera√ß√µes em regress√£o linear?",
                "difficulty": 4,
                "tags": [],
                "expected": "Intera√ß√£o significa que o efeito de x1 depende de x2 (ex.: desconto funciona diferente por segmento). Adicionar termo x1*x2 permite capturar isso.\nFaz sentido quando h√° justificativa de dom√≠nio e evid√™ncia nos dados; use regulariza√ß√£o/CV para evitar explos√£o de features."
              },
              {
                "id": "ch10_q11",
                "type": [
                  "missing"
                ],
                "prompt": "Como diagnosticar se a regress√£o m√∫ltipla est√° 'faltando vari√°veis importantes'?",
                "difficulty": 4,
                "tags": [],
                "expected": "Sinais: res√≠duos com padr√£o por segmentos, autocorrela√ß√£o, e erro alto em faixas espec√≠ficas. Verifique se h√° vari√°veis de confus√£o e se features dispon√≠veis no momento da previs√£o s√£o suficientes.\nCrie features derivadas (agrega√ß√µes, lags) e compare melhoria via CV."
              },
              {
                "id": "ch10_q12",
                "type": [
                  "leakage",
                  "pipeline"
                ],
                "prompt": "Explique o problema de 'data leakage' em regress√£o m√∫ltipla com exemplos t√≠picos em features agregadas.",
                "difficulty": 5,
                "tags": [],
                "expected": "Leakage comum: agrega√ß√µes calculadas usando dados futuros (ex.: m√©dia de compras do m√™s inteiro para prever no meio do m√™s), ou features calculadas ap√≥s o evento.\nEvite com janelas temporais corretas (rolling) e gera√ß√£o de features alinhada ao timestamp da previs√£o."
              },
              {
                "id": "ch10_q13",
                "type": [
                  "regressao_linear",
                  "multivariada"
                ],
                "prompt": "Por que padroniza√ß√£o √© cr√≠tica quando voc√™ usa regulariza√ß√£o (Ridge/Lasso/Elastic Net)?",
                "difficulty": 3,
                "tags": [],
                "expected": "A penaliza√ß√£o atua sobre o tamanho dos coeficientes. Se uma feature tem escala enorme, ela domina e √© penalizada de forma diferente.\nPadronizar coloca todas em escala compar√°vel, tornando a regulariza√ß√£o justa e o tuning (alpha/C) mais est√°vel."
              },
              {
                "id": "ch10_q14",
                "type": [
                  "regressao_linear",
                  "multicolinearidade"
                ],
                "prompt": "Explique como lidar com outliers em regress√£o m√∫ltipla sem simplesmente remov√™-los.",
                "difficulty": 4,
                "tags": [],
                "expected": "Use transforma√ß√µes (log), m√©tricas robustas (MAE), winsorization por regra de dom√≠nio, modelos robustos (HuberRegressor, RANSAC) ou segmenta√ß√£o.\nSempre valide impacto em CV e verifique se outliers s√£o casos reais relevantes."
              },
              {
                "id": "ch10_q15",
                "type": [
                  "regressao_linear",
                  "dummy"
                ],
                "prompt": "Descreva como voc√™ interpretaria coeficientes quando h√° one-hot encoding. O que muda na interpreta√ß√£o do intercepto?",
                "difficulty": 4,
                "tags": [],
                "expected": "Com one-hot, coeficientes representam diferen√ßa em rela√ß√£o √† categoria de refer√™ncia (baseline). O intercepto √© o valor previsto para a categoria base com num√©ricas em zero (ou m√©dia se padronizadas).\nPara interpreta√ß√£o, frequentemente √© melhor reverter a padroniza√ß√£o e usar exemplos concretos (cen√°rios)."
              },
              {
                "id": "ch10_q16",
                "type": [
                  "regressao_linear",
                  "interactions"
                ],
                "prompt": "Explique por que 'muitos atributos' podem piorar a regress√£o (mesmo linear). O que fazer quando p >> n?",
                "difficulty": 4,
                "tags": [],
                "expected": "Com muitas features e poucos dados, o modelo pode ajustar ru√≠do e ficar inst√°vel. Colinearidade e vari√¢ncia aumentam.\nUse regulariza√ß√£o, sele√ß√£o de features, redu√ß√£o de dimensionalidade, e principalmente mais dados. Valida√ß√£o cruzada √© indispens√°vel."
              },
              {
                "id": "ch10_q17",
                "type": [
                  "regressao_linear",
                  "regularizacao"
                ],
                "prompt": "Como comparar dois modelos de regress√£o m√∫ltipla de forma justa? Cite um protocolo.",
                "difficulty": 4,
                "tags": [],
                "expected": "Use o mesmo split/CV, mesma engenharia de features, e tuning com or√ßamento similar. Compare m√©dia e desvio das m√©tricas e fa√ßa an√°lise de erro por segmento.\nDepois, avalie no teste final e registre tudo para reprodutibilidade."
              },
              {
                "id": "ch10_q18",
                "type": [
                  "regressao_linear",
                  "adj_r2"
                ],
                "prompt": "Explique 'feature scaling' vs 'target scaling'. Quando faria scaling do target em regress√£o?",
                "difficulty": 4,
                "tags": [],
                "expected": "Scaling de features √© comum para modelos sens√≠veis a escala. Scaling do target √© √∫til quando y tem ordens de grandeza diferentes e o modelo se beneficia (ex.: SVR, redes neurais).\nAo escalar y, lembre de inverter a escala na predi√ß√£o e avaliar m√©tricas na unidade original."
              },
              {
                "id": "ch10_q19",
                "type": [
                  "pipeline",
                  "scaling"
                ],
                "prompt": "Descreva um caso onde regress√£o linear m√∫ltipla √© uma m√° escolha e justifique outro modelo.",
                "difficulty": 4,
                "tags": [],
                "expected": "Se h√° forte n√£o linearidade, intera√ß√µes complexas e limites, linear pode falhar (alto erro e res√≠duos estruturados). Exemplos: precifica√ß√£o com efeitos de satura√ß√£o.\nConsidere √°rvores/Random Forest/Gradient Boosting ou SVR com kernel, e compare via CV e interpretabilidade."
              },
              {
                "id": "ch10_q20",
                "type": [
                  "diagnostico",
                  "residuos"
                ],
                "prompt": "Quais gr√°ficos e diagn√≥sticos voc√™ apresentaria para convencer que o modelo √© 'bom o suficiente' e onde ele falha?",
                "difficulty": 5,
                "tags": [],
                "expected": "Mostre: real vs predito, res√≠duos vs predito, erro por segmento, distribui√ß√£o de res√≠duos e import√¢ncia/coeficientes (com estabilidade). Inclua baseline.\nTamb√©m mostre casos de maior erro e explique limites (ex.: faixa sem dados, drift)."
              }
            ]
          },
          {
            "chapter": 11,
            "id": "regressao_polinomial",
            "title": "Regress√£o Polinomial",
            "keyTopics": [
              "regress√£o polinomial",
              "carga dados",
              "X/y",
              "split + CV",
              "treino",
              "visualiza√ß√£o teste",
              "predi√ß√£o"
            ],
            "questions": [
              {
                "id": "ch11_q01",
                "type": [
                  "regress√£o_polinomial"
                ],
                "prompt": "Explique a motiva√ß√£o da Regress√£o Polinomial. Por que ela ainda √© uma regress√£o linear 'por dentro'?",
                "difficulty": 3,
                "tags": [],
                "expected": "Ela permite capturar curvatura adicionando termos x¬≤, x¬≥, etc. Apesar de n√£o ser linear em x, √© linear nos par√¢metros (coeficientes) desses termos, ent√£o pode ser treinada com regress√£o linear sobre features expandidas."
              },
              {
                "id": "ch11_q02",
                "type": [
                  "overfitting",
                  "model_selection"
                ],
                "prompt": "O que faz o PolynomialFeatures no scikit-learn? O que significa include_bias e interaction_only?",
                "difficulty": 4,
                "tags": [],
                "expected": "PolynomialFeatures gera colunas elevadas a pot√™ncias e (opcionalmente) intera√ß√µes entre features. include_bias adiciona a coluna de 1 (intercepto). interaction_only gera s√≥ intera√ß√µes, sem pot√™ncias individuais acima de 1.\nEle pode explodir dimensionalidade; use com cuidado."
              },
              {
                "id": "ch11_q03",
                "type": [
                  "valida√ß√£o"
                ],
                "prompt": "Por que o grau do polin√¥mio √© um hiperpar√¢metro cr√≠tico? Como escolher grau de forma rigorosa?",
                "difficulty": 4,
                "tags": [],
                "expected": "Grau controla complexidade: baixo grau pode underfit; alto grau overfit e extrapola mal. Escolha via valida√ß√£o cruzada e compare m√©tricas + gr√°ficos de res√≠duos.\nEvite escolher olhando o teste; use CV, e finalize em um conjunto de teste separado."
              },
              {
                "id": "ch11_q04",
                "type": [
                  "pipeline"
                ],
                "prompt": "Explique por que regress√£o polinomial tende a extrapolar mal. D√™ um exemplo intuitivo.",
                "difficulty": 4,
                "tags": [],
                "expected": "Polin√¥mios de grau alto podem crescer rapidamente fora do intervalo observado, gerando previs√µes absurdas. Mesmo grau baixo pode seguir tend√™ncia errada al√©m do suporte.\nEx.: ajuste em 0..10 e prever em 20 pode 'explodir'. Mitigue com dom√≠nio restrito ou modelos com satura√ß√£o."
              },
              {
                "id": "ch11_q05",
                "type": [
                  "visualiza√ß√£o"
                ],
                "prompt": "Mostre (conceitualmente) como montar um Pipeline: StandardScaler -> PolynomialFeatures -> LinearRegression. Por que a ordem importa?",
                "difficulty": 4,
                "tags": [],
                "expected": "A ordem garante que a expans√£o polinomial seja feita a partir de features em escala controlada (quando necess√°rio) e que o modelo seja treinado com as mesmas transforma√ß√µes.\nEm geral: (1) imputar, (2) escalar, (3) expandir polin√¥mio, (4) regress√£o/regulariza√ß√£o."
              },
              {
                "id": "ch11_q06",
                "type": [
                  "overfitting"
                ],
                "prompt": "Padroniza√ß√£o √© necess√°ria em regress√£o polinomial? Explique o motivo e o que pode acontecer sem ela.",
                "difficulty": 4,
                "tags": [],
                "expected": "√â recomendada porque termos x¬≤, x¬≥ amplificam escala e podem causar instabilidade num√©rica e coeficientes enormes. Com regulariza√ß√£o, √© praticamente obrigat√≥ria.\nSem padroniza√ß√£o, o modelo pode ser dif√≠cil de ajustar e extremamente sens√≠vel a pequenas varia√ß√µes."
              },
              {
                "id": "ch11_q07",
                "type": [
                  "predi√ß√£o"
                ],
                "prompt": "Explique como interpretar coeficientes em um modelo polinomial. Por que interpreta√ß√£o direta √© dif√≠cil?",
                "difficulty": 5,
                "tags": [],
                "expected": "Coeficientes n√£o t√™m interpreta√ß√£o simples como 'cada 1 unidade em x muda y em Œ≤' porque o efeito depende de x (derivada). Al√©m disso, termos s√£o correlacionados.\nPara interpretar, use gr√°ficos de curva, derivadas locais, e 'efeito marginal' em pontos espec√≠ficos."
              },
              {
                "id": "ch11_q08",
                "type": [
                  "tradeoff"
                ],
                "prompt": "O que √© overfitting em regress√£o polinomial e como ele aparece em gr√°ficos?",
                "difficulty": 4,
                "tags": [],
                "expected": "Overfitting aparece como curva 'ondulada' que passa perto dos pontos de treino, mas erra em regi√µes novas. Em gr√°ficos: muita oscila√ß√£o, grandes varia√ß√µes locais e res√≠duos pequenos no treino, grandes no teste.\nUse CV, regulariza√ß√£o e escolha de grau apropriada."
              },
              {
                "id": "ch11_q09",
                "type": [
                  "feature_engineering"
                ],
                "prompt": "Compare regress√£o polinomial com splines e com √°rvores de decis√£o. Em quais cen√°rios cada um √© melhor?",
                "difficulty": 5,
                "tags": [],
                "expected": "Polinomial √© simples, mas extrapola mal e pode oscilar. Splines (piecewise) modelam curvatura de forma est√°vel e local. √Årvores capturam n√£o linearidade e intera√ß√µes sem engenharia expl√≠cita, mas podem ser menos suaves.\nEscolha pelo tipo de rela√ß√£o e pela necessidade de suavidade/interpreta√ß√£o."
              },
              {
                "id": "ch11_q10",
                "type": [
                  "dimensionalidade"
                ],
                "prompt": "Explique como usar regulariza√ß√£o (Ridge/Lasso) em regress√£o polinomial e por que isso ajuda.",
                "difficulty": 4,
                "tags": [],
                "expected": "Com muitos termos, a vari√¢ncia aumenta. Ridge encolhe coeficientes e reduz oscila√ß√µes; Lasso pode zerar termos e simplificar.\nCombine com padroniza√ß√£o e CV para escolher alpha; isso reduz overfitting e melhora generaliza√ß√£o."
              },
              {
                "id": "ch11_q11",
                "type": [
                  "avalia√ß√£o"
                ],
                "prompt": "Como avaliar um modelo polinomial al√©m das m√©tricas? Cite 3 diagn√≥sticos importantes.",
                "difficulty": 4,
                "tags": [],
                "expected": "Diagn√≥sticos: (1) real vs predito para ver tend√™ncia; (2) res√≠duos vs x/predito para detectar padr√µes; (3) sensibilidade a outliers e estabilidade por bootstrap.\nTamb√©m √© √∫til comparar contra baseline e modelos alternativos (linear, √°rvore)."
              },
              {
                "id": "ch11_q12",
                "type": [
                  "boas_praticas"
                ],
                "prompt": "Explique o impacto de outliers em regress√£o polinomial e estrat√©gias para reduzir o dano.",
                "difficulty": 4,
                "tags": [],
                "expected": "Outliers podem puxar a curva e aumentar oscila√ß√µes. Estrat√©gias: tratar outliers por regra de dom√≠nio, usar perdas robustas (Huber/RANSAC), transforma√ß√µes (log) e limitar grau.\nSempre valide impacto em CV e inspecione casos extremos."
              },
              {
                "id": "ch11_q13",
                "type": [
                  "polinomial",
                  "features"
                ],
                "prompt": "Como voc√™ faria sele√ß√£o autom√°tica do melhor grau (1..N) usando GridSearchCV e Pipeline sem vazamento?",
                "difficulty": 5,
                "tags": [],
                "expected": "Monte Pipeline com PolynomialFeatures + modelo (ex.: Ridge). Use GridSearchCV no par√¢metro degree e alpha, com CV. O GridSearch ajusta tudo dentro de cada dobra, evitando leakage.\nDepois, avalie o melhor pipeline no teste final e registre par√¢metros."
              },
              {
                "id": "ch11_q14",
                "type": [
                  "polinomial",
                  "grau"
                ],
                "prompt": "Explique 'interaction terms' em regress√£o polinomial com m√∫ltiplas features. Por que isso explode dimensionalidade?",
                "difficulty": 5,
                "tags": [],
                "expected": "Com v√°rias features, PolynomialFeatures cria combina√ß√µes (x1*x2, x1¬≤*x2, etc.). O n√∫mero de termos cresce combinatoriamente com o grau e a quantidade de features.\nIsso aumenta custo e overfitting; use grau baixo, sele√ß√£o/regulariza√ß√£o e, se preciso, limitar intera√ß√µes."
              },
              {
                "id": "ch11_q15",
                "type": [
                  "polinomial",
                  "sele√ß√£o_grau"
                ],
                "prompt": "Quando a regress√£o polinomial √© uma escolha ruim? D√™ dois sinais fortes.",
                "difficulty": 4,
                "tags": [],
                "expected": "Sinais: (1) rela√ß√£o muda por segmentos e requer regras diferentes (n√£o uma curva global); (2) muitos atributos e intera√ß√µes complexas; (3) previs√£o fora do intervalo (extrapola√ß√£o) √© importante.\nNesses casos, prefira modelos baseados em √°rvores ou m√©todos locais (KNN/splines)."
              },
              {
                "id": "ch11_q16",
                "type": [
                  "polinomial",
                  "scaling"
                ],
                "prompt": "Explique a diferen√ßa entre ajustar polin√¥mio em uma vari√°vel vs ajustar em v√°rias. O que muda na visualiza√ß√£o?",
                "difficulty": 4,
                "tags": [],
                "expected": "Em 1D, voc√™ visualiza facilmente a curva. Em v√°rias vari√°veis, a superf√≠cie √© dif√≠cil de plotar e interpretar; voc√™ precisa de cortes (fixar vari√°veis) e an√°lises de sensibilidade.\nTamb√©m aumenta muito o risco de overfitting por intera√ß√µes."
              },
              {
                "id": "ch11_q17",
                "type": [
                  "polinomial",
                  "regularizacao"
                ],
                "prompt": "Como voc√™ escolheria o limite m√°ximo de grau (N) antes de fazer grid search?",
                "difficulty": 4,
                "tags": [],
                "expected": "Baseie em: tamanho de dataset (mais dados permitem mais complexidade), ru√≠do, dom√≠nio (curvas suaves tendem a precisar de graus baixos) e custo computacional.\nPr√°tica: come√ßar com 1..5, validar; s√≥ aumentar se houver evid√™ncia clara de underfitting."
              },
              {
                "id": "ch11_q18",
                "type": [
                  "polinomial",
                  "under_over"
                ],
                "prompt": "Explique como detectar underfitting em regress√£o polinomial e como corrigir.",
                "difficulty": 4,
                "tags": [],
                "expected": "Underfitting: erro alto em treino e teste, res√≠duos com padr√£o (curva) e previs√µes sistematicamente acima/abaixo em regi√µes.\nCorrija aumentando grau com CV, adicionando features, transformando vari√°veis ou escolhendo modelo mais flex√≠vel."
              },
              {
                "id": "ch11_q19",
                "type": [
                  "polinomial",
                  "pipeline"
                ],
                "prompt": "D√™ um exemplo de problema real onde um modelo polinomial faz sentido e outro onde ele √© perigoso.",
                "difficulty": 4,
                "tags": [],
                "expected": "Faz sentido: rela√ß√£o f√≠sica suave em faixa limitada (ex.: consumo vs velocidade em intervalo). Perigoso: pre√ßos/risco com mudan√ßas abruptas e regimes (mercado) ou quando voc√™ precisa extrapolar para valores nunca vistos.\nSempre conecte escolha do modelo ao dom√≠nio e ao protocolo de valida√ß√£o."
              },
              {
                "id": "ch11_q20",
                "type": [
                  "polinomial",
                  "interpreta√ß√£o"
                ],
                "prompt": "Explique como documentar um experimento com regress√£o polinomial para que outra pessoa consiga reproduzir e auditar.",
                "difficulty": 5,
                "tags": [],
                "expected": "Documente: dataset/vers√£o, split/CV, grau testado, par√¢metros (alpha, scaler), m√©tricas e gr√°ficos de diagn√≥stico. Salve o pipeline (joblib) e liste colunas.\nSem isso, resultados n√£o s√£o verific√°veis e o modelo n√£o √© confi√°vel para decis√£o."
              }
            ]
          },
          {
            "chapter": 12,
            "id": "arvores_de_decisao",
            "title": "√Årvores de Decis√£o",
            "keyTopics": [
              "√°rvore de decis√£o para classifica√ß√£o",
              "carga bibliotecas e dados",
              "divis√µes por regras",
              "interpretabilidade"
            ],
            "questions": [
              {
                "id": "ch12_q01",
                "type": [
                  "arvore_decisao"
                ],
                "prompt": "Explique a intui√ß√£o de uma √Årvore de Decis√£o para classifica√ß√£o. Como ela transforma dados em regras?",
                "difficulty": 3,
                "tags": [],
                "expected": "Uma √°rvore divide o espa√ßo de features em regi√µes por perguntas do tipo 'x_j <= limiar?'. Cada n√≥ escolhe a divis√£o que melhor separa classes segundo um crit√©rio (Gini/Entropia).\nO resultado √© um conjunto de regras interpret√°veis que mapeiam regi√µes para uma classe."
              },
              {
                "id": "ch12_q02",
                "type": [
                  "arvore_decisao"
                ],
                "prompt": "Compare Gini e Entropia. Eles costumam levar a √°rvores muito diferentes?",
                "difficulty": 4,
                "tags": [],
                "expected": "Ambos medem impureza: Gini √© mais simples e costuma ser um pouco mais r√°pido; entropia vem de teoria da informa√ß√£o. Na pr√°tica, frequentemente produzem √°rvores parecidas, mas podem escolher divis√µes diferentes em empates.\nO mais importante √© controlar complexidade (profundidade, min_samples)."
              },
              {
                "id": "ch12_q03",
                "type": [
                  "pipeline"
                ],
                "prompt": "O que √© overfitting em √°rvores? Cite hiperpar√¢metros que controlam complexidade.",
                "difficulty": 3,
                "tags": [],
                "expected": "√Årvores podem memorizar ru√≠do criando muitos n√≥s. Controle com max_depth, min_samples_split, min_samples_leaf, max_features e ccp_alpha (poda).\nUse valida√ß√£o cruzada para ajustar esses par√¢metros e evitar √°rvore gigante com m√©tricas infladas no treino."
              },
              {
                "id": "ch12_q04",
                "type": [
                  "arvore_decisao"
                ],
                "prompt": "Explique poda (pruning) e o papel de ccp_alpha. Por que podar pode melhorar generaliza√ß√£o?",
                "difficulty": 4,
                "tags": [],
                "expected": "Poda remove ramos com pouco ganho real, reduzindo vari√¢ncia. ccp_alpha (cost-complexity pruning) penaliza √°rvores complexas.\nPodar simplifica regras, melhora generaliza√ß√£o e interpretabilidade, especialmente quando h√° ru√≠do e poucos dados."
              },
              {
                "id": "ch12_q05",
                "type": [
                  "tradeoff"
                ],
                "prompt": "Como interpretar 'feature importance' em √°rvores? Quais s√£o duas armadilhas comuns?",
                "difficulty": 4,
                "tags": [],
                "expected": "Importance mede redu√ß√£o m√©dia de impureza por feature. Armadilhas: (1) vi√©s para vari√°veis com muitos n√≠veis/valores; (2) correla√ß√£o entre features divide a import√¢ncia e pode esconder efeito.\nValide com permuta√ß√£o (permutation importance) e an√°lise de erros por segmento."
              },
              {
                "id": "ch12_q06",
                "type": [
                  "overfitting"
                ],
                "prompt": "Como √°rvores lidam com escalas de features? Voc√™ precisa padronizar como em SVM/KNN?",
                "difficulty": 2,
                "tags": [],
                "expected": "√Årvores s√£o invariantes √† escala: decis√µes por limiar n√£o dependem de unidades como dist√¢ncia. Em geral, n√£o precisam de padroniza√ß√£o.\nAinda assim, pr√©-processamento pode ser necess√°rio para missing, categorias e vazamento, mas n√£o por escala."
              },
              {
                "id": "ch12_q07",
                "type": [
                  "avalia√ß√£o"
                ],
                "prompt": "Explique como tratar vari√°veis categ√≥ricas com DecisionTreeClassifier no ecossistema scikit-learn.",
                "difficulty": 4,
                "tags": [],
                "expected": "O sklearn tradicional requer n√∫meros; categorias precisam ser codificadas (OneHot/Ordinal). OneHot √© seguro para categorias nominais.\nCuidado com alta cardinalidade (muitas colunas) e com leakage em categorias raras; valide e, se preciso, agrupe categorias."
              },
              {
                "id": "ch12_q08",
                "type": [
                  "desbalanceamento"
                ],
                "prompt": "Explique por que √°rvores s√£o atraentes em interpretabilidade, mas ainda podem ser dif√≠ceis de explicar quando crescem.",
                "difficulty": 3,
                "tags": [],
                "expected": "√Årvores pequenas viram regras f√°ceis. √Årvores grandes t√™m dezenas/centenas de n√≥s e ficam t√£o complexas quanto modelos 'caixa-preta'.\nPor isso, controle profundidade, use poda e prefira explicar com caminhos principais, exemplos e m√©tricas por segmento."
              },
              {
                "id": "ch12_q09",
                "type": [
                  "arvores",
                  "split"
                ],
                "prompt": "Como visualizar uma √°rvore e extrair regras √∫teis para comunica√ß√£o?",
                "difficulty": 3,
                "tags": [],
                "expected": "Use plot_tree/export_text para visualizar e ler splits. Foque nos primeiros n√≠veis (maior ganho) e em caminhos que cobrem boa parte dos dados.\nTraduza regras em linguagem de neg√≥cio e valide com exemplos reais, mostrando casos corretos e erros."
              },
              {
                "id": "ch12_q10",
                "type": [
                  "arvores",
                  "gini_entropy"
                ],
                "prompt": "Explique como avaliar uma √°rvore em dados desbalanceados. Quais m√©tricas e ajustes voc√™ consideraria?",
                "difficulty": 4,
                "tags": [],
                "expected": "Use matriz de confus√£o, precision/recall/F1, PR-AUC e ajuste de threshold (se usar probabilidades). Tamb√©m considere class_weight para penalizar classe rara.\nEm desbalanceamento forte, uma √°rvore pode prever majorit√°ria; portanto, estratifique splits e fa√ßa an√°lise por segmento."
              },
              {
                "id": "ch12_q11",
                "type": [
                  "arvores",
                  "profundidade"
                ],
                "prompt": "O que s√£o probabilidades em √°rvores (predict_proba)? Elas s√£o bem calibradas?",
                "difficulty": 5,
                "tags": [],
                "expected": "As probabilidades s√£o propor√ß√µes de classes nas folhas. Em √°rvores profundas, podem ficar extremas (0 ou 1) e n√£o calibradas.\nSe voc√™ precisa de probabilidades confi√°veis, use calibra√ß√£o (CalibratedClassifierCV) ou modelos ensemble (Random Forest/GBM)."
              },
              {
                "id": "ch12_q12",
                "type": [
                  "arvores",
                  "pruning"
                ],
                "prompt": "Explique o que muda quando voc√™ passa de √Årvore de Decis√£o para Random Forest ou Gradient Boosting.",
                "difficulty": 4,
                "tags": [],
                "expected": "√Årvore √∫nica √© interpret√°vel, mas inst√°vel. Random Forest reduz vari√¢ncia ao agregar muitas √°rvores com amostragem; Boosting reduz vi√©s ao combinar √°rvores fracas sequencialmente.\nEm geral, ensembles performam melhor, mas explica√ß√£o fica mais indireta (feature importance, SHAP)."
              },
              {
                "id": "ch12_q13",
                "type": [
                  "arvores",
                  "feature_importance"
                ],
                "prompt": "Como detectar instabilidade de uma √°rvore? D√™ um m√©todo pr√°tico.",
                "difficulty": 4,
                "tags": [],
                "expected": "√Årvores mudam muito com pequenas varia√ß√µes nos dados. Teste com bootstrap: reamostre o dataset e treine v√°rias √°rvores; compare splits/feature importance e m√©tricas.\nSe variar muito, use poda/regulariza√ß√£o ou ensembles."
              },
              {
                "id": "ch12_q14",
                "type": [
                  "arvores",
                  "missing"
                ],
                "prompt": "Explique a diferen√ßa entre min_samples_leaf e max_depth no controle de overfitting. Quando preferir ajustar um ou outro?",
                "difficulty": 4,
                "tags": [],
                "expected": "max_depth limita altura; min_samples_leaf garante tamanho m√≠nimo de folha. min_samples_leaf √© √≥timo para evitar folhas com poucos exemplos (ru√≠do) e tende a produzir regras mais gerais.\nComece com min_samples_leaf para robustez e ajuste depth para interpretabilidade/performance."
              },
              {
                "id": "ch12_q15",
                "type": [
                  "arvores",
                  "categoricas"
                ],
                "prompt": "Como lidar com dados com muitos missing antes de uma √°rvore no sklearn? O que n√£o fazer?",
                "difficulty": 4,
                "tags": [],
                "expected": "Impute missing (mediana/moda) dentro de Pipeline para evitar leakage. Tamb√©m pode criar indicador de missing.\nN√£o impute usando todo o dataset antes do split. E n√£o remova colunas cegamente sem entender se missing √© informativo."
              },
              {
                "id": "ch12_q16",
                "type": [
                  "arvores",
                  "ensemble"
                ],
                "prompt": "Descreva um mini-caso: voc√™ quer explicar a decis√£o de um modelo para auditoria. Como voc√™ usaria uma √°rvore pequena como 'modelo substituto'?",
                "difficulty": 5,
                "tags": [],
                "expected": "Treine um modelo melhor (ex.: ensemble) e depois treine uma √°rvore pequena para aproximar suas decis√µes em um conjunto de dados (surrogate model).\nUse a √°rvore para explicar regras gerais e valide fidelidade (qu√£o bem imita o modelo) + exemplos de decis√µes. N√£o confunda surrogate com verdade causal."
              }
            ]
          },
          {
            "chapter": 13,
            "id": "regressao_logistica",
            "title": "Regress√£o Log√≠stica",
            "keyTopics": [
              "vis√£o geral",
              "raz√£o das chances (odds)",
              "sigmoide",
              "implementa√ß√£o python",
              "dataset",
              "carregar libs/dados",
              "EDA",
              "estat√≠sticas descritivas",
              "an√°lise por gr√°ficos",
              "features: Gravidezes, Glicose, PD, DobraTr√≠ceps, Insulina, IMC, DPF, Idade",
              "correla√ß√µes",
              "conclus√µes"
            ],
            "questions": [
              {
                "id": "ch13_q01",
                "type": [
                  "logistica"
                ],
                "prompt": "Explique a motiva√ß√£o da Regress√£o Log√≠stica. Por que ela √© um classificador e n√£o uma regress√£o 'de verdade'?",
                "difficulty": 3,
                "tags": [],
                "expected": "Ela modela a probabilidade de uma classe (y=1) como fun√ß√£o das features via sigmoide. Embora use 'regress√£o' no nome, o alvo √© categ√≥rico e o modelo otimiza log-loss para classifica√ß√£o.\nO output pode ser probabilidade; a classe vem de um threshold."
              },
              {
                "id": "ch13_q02",
                "type": [
                  "odds"
                ],
                "prompt": "Defina odds e log-odds (logit). Como isso aparece na f√≥rmula da Regress√£o Log√≠stica?",
                "difficulty": 4,
                "tags": [],
                "expected": "Odds = p/(1-p). Log-odds = log(p/(1-p)). A Regress√£o Log√≠stica assume que log-odds √© linear nas features: logit(p)=Œ≤0+Œ≤¬∑x.\nIsso d√° interpretabilidade: mudan√ßas em x afetam odds multiplicativamente."
              },
              {
                "id": "ch13_q03",
                "type": [
                  "sigmoide"
                ],
                "prompt": "Explique a fun√ß√£o sigmoide e o que acontece com p quando Œ≤¬∑x cresce muito positivo ou muito negativo.",
                "difficulty": 2,
                "tags": [],
                "expected": "Sigmoide mapeia qualquer n√∫mero real para (0,1). Se Œ≤¬∑x √© muito positivo, p tende a 1; se muito negativo, p tende a 0.\nIsso cria decis√£o suave e permite treinar por gradiente/otimiza√ß√£o convexa (no caso padr√£o)."
              },
              {
                "id": "ch13_q04",
                "type": [
                  "classifica√ß√£o"
                ],
                "prompt": "Como interpretar um coeficiente Œ≤i em termos de odds ratio? D√™ um exemplo com n√∫meros.",
                "difficulty": 4,
                "tags": [],
                "expected": "Para 1 unidade em xi, o log-odds muda em Œ≤i; as odds multiplicam por exp(Œ≤i). Ex.: Œ≤i=0,7 => exp(0,7)‚âà2,01: odds dobram.\nCuidado com unidade/escala; padronize para comparar magnitudes entre features."
              },
              {
                "id": "ch13_q05",
                "type": [
                  "pipeline"
                ],
                "prompt": "Compare log-loss com accuracy. Por que log-loss √© mais informativa durante o treino?",
                "difficulty": 4,
                "tags": [],
                "expected": "Accuracy s√≥ olha acerto/erro ap√≥s threshold; ignora confian√ßa. Log-loss penaliza probabilidades erradas com for√ßa, incentivando probabilidades calibradas.\nPor isso, log-loss detecta melhorias mesmo quando accuracy muda pouco, e √© melhor para otimizar modelos probabil√≠sticos."
              },
              {
                "id": "ch13_q06",
                "type": [
                  "dados"
                ],
                "prompt": "Explique decis√£o por threshold. Como voc√™ escolheria um threshold alinhado ao custo de FP/FN?",
                "difficulty": 4,
                "tags": [],
                "expected": "Escolha threshold para minimizar custo esperado: custo_FP*FP + custo_FN*FN. Use curva PR/ROC e avalie precision/recall em thresholds.\nEm fraude, priorize recall; em cr√©dito, priorize precis√£o para evitar negar bons clientes; documente o crit√©rio."
              },
              {
                "id": "ch13_q07",
                "type": [
                  "eda"
                ],
                "prompt": "O que muda entre classifica√ß√£o bin√°ria, multinomial (softmax) e one-vs-rest em Regress√£o Log√≠stica?",
                "difficulty": 4,
                "tags": [],
                "expected": "Bin√°ria usa sigmoide. Multinomial usa softmax e aprende uma matriz de coeficientes para classes; tende a ser melhor quando classes competem.\nOne-vs-rest treina um classificador por classe; pode ser mais simples, mas pode gerar probabilidades inconsistentes entre classes."
              },
              {
                "id": "ch13_q08",
                "type": [
                  "eda",
                  "visualiza√ß√£o"
                ],
                "prompt": "Explique por que padroniza√ß√£o costuma ser importante em Regress√£o Log√≠stica (especialmente com regulariza√ß√£o).",
                "difficulty": 3,
                "tags": [],
                "expected": "O otimizador converge melhor quando features est√£o em escala similar. Com regulariza√ß√£o, a penaliza√ß√£o depende da escala: uma feature grande pode ser penalizada de forma diferente.\nPadronizar melhora estabilidade, tuning e interpretabilidade (coeficientes compar√°veis)."
              },
              {
                "id": "ch13_q09",
                "type": [
                  "features"
                ],
                "prompt": "O que √© regulariza√ß√£o em Regress√£o Log√≠stica? Explique o par√¢metro C no scikit-learn.",
                "difficulty": 4,
                "tags": [],
                "expected": "Regulariza√ß√£o controla complexidade e evita overfitting. Em sklearn, C √© o inverso da for√ßa de regulariza√ß√£o: C alto = pouca regulariza√ß√£o; C baixo = forte regulariza√ß√£o.\nEscolha C via valida√ß√£o cruzada; com L1, pode haver sele√ß√£o de features."
              },
              {
                "id": "ch13_q10",
                "type": [
                  "features",
                  "eda"
                ],
                "prompt": "Compare L1 e L2 em Regress√£o Log√≠stica. Quando L1 √© √∫til? Qual risco em features correlacionadas?",
                "difficulty": 4,
                "tags": [],
                "expected": "L2 encolhe coeficientes e √© est√°vel. L1 pode zerar coeficientes, √∫til para sele√ß√£o e modelos esparsos.\nEm features correlacionadas, L1 escolhe uma arbitrariamente; valide estabilidade e considere Elastic Net."
              },
              {
                "id": "ch13_q11",
                "type": [
                  "missing",
                  "features"
                ],
                "prompt": "Explique como lidar com classes desbalanceadas em Regress√£o Log√≠stica (pesos, m√©tricas e amostragem).",
                "difficulty": 4,
                "tags": [],
                "expected": "Use class_weight='balanced' ou pesos customizados, avalie com PR-AUC/F1/recall@precision, e ajuste threshold. Se necess√°rio, reamostragem (under/over/SMOTE) dentro do CV.\nN√£o use apenas accuracy; valide por segmento e monitore em produ√ß√£o."
              },
              {
                "id": "ch13_q12",
                "type": [
                  "features",
                  "escala"
                ],
                "prompt": "O que √© calibra√ß√£o de probabilidades? Como verificar e corrigir em Regress√£o Log√≠stica?",
                "difficulty": 5,
                "tags": [],
                "expected": "Calibra√ß√£o significa que probabilidades refletem frequ√™ncias reais. Verifique com reliability diagram e Brier score.\nCorrija com Platt scaling/isotonic (CalibratedClassifierCV) ou com regulariza√ß√£o/feature engineering; n√£o confunda boa separa√ß√£o com boa calibra√ß√£o."
              },
              {
                "id": "ch13_q13",
                "type": [
                  "features",
                  "correla√ß√£o"
                ],
                "prompt": "Explique a rela√ß√£o entre Regress√£o Log√≠stica e fronteira de decis√£o linear.",
                "difficulty": 3,
                "tags": [],
                "expected": "Como logit(p)=Œ≤0+Œ≤¬∑x, a fronteira onde p=0,5 √© Œ≤0+Œ≤¬∑x=0, um hiperplano. Logo, no espa√ßo original, a decis√£o √© linear.\nPara fronteiras n√£o lineares, use features n√£o lineares (polin√¥mios) ou kernels/modelos de √°rvore."
              },
              {
                "id": "ch13_q14",
                "type": [
                  "features"
                ],
                "prompt": "Como voc√™ detectaria overfitting em Regress√£o Log√≠stica e como mitig√°-lo?",
                "difficulty": 4,
                "tags": [],
                "expected": "Sinais: log-loss/erro muito melhor no treino que no teste, coeficientes grandes e inst√°veis. Mitiga√ß√£o: mais regulariza√ß√£o (C menor), remover ru√≠do, selecionar features, reduzir dimensionalidade e usar CV.\nTamb√©m avalie drift e leakage, que podem inflar resultados."
              },
              {
                "id": "ch13_q15",
                "type": [
                  "correla√ß√£o"
                ],
                "prompt": "Explique o papel de 'solver' no scikit-learn (lbfgs, liblinear, saga). Quando isso importa?",
                "difficulty": 4,
                "tags": [],
                "expected": "Solvers s√£o algoritmos de otimiza√ß√£o. liblinear √© bom para datasets menores e L1/L2 bin√°rio; lbfgs √© padr√£o para multinomial; saga escala melhor em grandes dados e suporta elastic net.\nImporta para desempenho, suporte a penalidades e converg√™ncia."
              },
              {
                "id": "ch13_q16",
                "type": [
                  "correla√ß√£o",
                  "modelagem"
                ],
                "prompt": "Como tratar vari√°veis categ√≥ricas antes da Regress√£o Log√≠stica e por que OneHotEncoder costuma ser prefer√≠vel?",
                "difficulty": 4,
                "tags": [],
                "expected": "Regr. log√≠stica assume rela√ß√£o linear em entradas num√©ricas. Para categorias, OneHot evita impor ordem artificial.\nOrdinal encoding pode criar dist√¢ncia falsa. Use OneHot com handle_unknown e, se alta cardinalidade, considere hashing/target encoding com cuidado e CV para evitar leakage."
              },
              {
                "id": "ch13_q17",
                "type": [
                  "correla√ß√£o"
                ],
                "prompt": "Explique o risco de target encoding e como faz√™-lo sem vazamento.",
                "difficulty": 5,
                "tags": [],
                "expected": "Target encoding usa estat√≠stica do target por categoria; se calculado no dataset inteiro, vaza r√≥tulo. Fa√ßa dentro de CV (encoding por dobra) e com smoothing.\nValide em teste; sem isso, m√©tricas ficam infladas e quebram em produ√ß√£o."
              },
              {
                "id": "ch13_q18",
                "type": [
                  "m√©tricas"
                ],
                "prompt": "O que √© matriz de confus√£o para log√≠stica e como voc√™ explicaria FP vs FN para stakeholders?",
                "difficulty": 3,
                "tags": [],
                "expected": "Matriz de confus√£o separa acertos/erros por tipo. FP: alerta falso; FN: caso real perdido.\nTraduza em custo: FP pode gerar trabalho ou negar clientes; FN pode causar perda (fraude n√£o detectada). Decis√£o de threshold depende disso."
              },
              {
                "id": "ch13_q19",
                "type": [
                  "threshold"
                ],
                "prompt": "Explique curva ROC e PR. Em qual cen√°rio voc√™ preferiria PR e por qu√™?",
                "difficulty": 4,
                "tags": [],
                "expected": "ROC mostra trade-off TPR vs FPR; PR mostra precis√£o vs recall. Em desbalanceamento, ROC pode parecer bom mesmo com muitos FP.\nPR foca na classe positiva e √© mais alinhada a problemas raros (fraude, intrus√£o)."
              },
              {
                "id": "ch13_q20",
                "type": [
                  "m√©tricas",
                  "matriz_confus√£o"
                ],
                "prompt": "Como voc√™ faria an√°lise de erros (error analysis) em um classificador log√≠stico para aprender com os erros?",
                "difficulty": 4,
                "tags": [],
                "expected": "Colete FP e FN, agrupe por segmento (idade, regi√£o, categoria), veja padr√µes e features ausentes. Inspecione casos extremos de probabilidade.\nIsso gera hip√≥teses de novas features, limpeza de r√≥tulos e ajuste de threshold/pondera√ß√£o."
              },
              {
                "id": "ch13_q21",
                "type": [
                  "eda",
                  "pr√©-processamento"
                ],
                "prompt": "Explique como lidar com dados com outliers e features assim√©tricas em Regress√£o Log√≠stica.",
                "difficulty": 4,
                "tags": [],
                "expected": "Outliers e assimetria podem distorcer coeficientes. Use transforma√ß√µes (log, winsor), padroniza√ß√£o robusta e regulariza√ß√£o. Verifique influ√™ncia por an√°lise de coeficientes e performance por faixa.\nPara dados com forte n√£o linearidade, considere modelos alternativos."
              },
              {
                "id": "ch13_q22",
                "type": [
                  "conclus√µes"
                ],
                "prompt": "O que √© separa√ß√£o perfeita (perfect separation) e por que isso pode ser um problema em Regress√£o Log√≠stica?",
                "difficulty": 5,
                "tags": [],
                "expected": "Separa√ß√£o perfeita ocorre quando uma combina√ß√£o de features separa classes sem erro; coeficientes tendem a infinito e o ajuste fica inst√°vel.\nMitigue com regulariza√ß√£o, remover feature leakage, ou usar m√©todos bayesianos/penalizados."
              },
              {
                "id": "ch13_q23",
                "type": [
                  "eda"
                ],
                "prompt": "Explique como usar Regress√£o Log√≠stica como baseline forte e quando ela costuma ganhar de modelos mais complexos.",
                "difficulty": 3,
                "tags": [],
                "expected": "Ela √© r√°pida, robusta e interpret√°vel. Com boas features e dados tabulares, pode competir com modelos complexos, especialmente quando rela√ß√£o √© quase linear e o dataset n√£o √© enorme.\nGanha quando simplicidade, explicabilidade e estabilidade s√£o prioridades."
              },
              {
                "id": "ch13_q24",
                "type": [
                  "interpreta√ß√£o"
                ],
                "prompt": "Como voc√™ reportaria e interpretaria coeficientes quando as features foram padronizadas?",
                "difficulty": 4,
                "tags": [],
                "expected": "Coeficientes correspondem a varia√ß√£o em log-odds por 1 desvio padr√£o de aumento na feature. Isso facilita comparar import√¢ncia relativa entre features.\nPara comunica√ß√£o, converta para odds ratio e use exemplos de cen√°rio (antes/depois) com valores reais."
              },
              {
                "id": "ch13_q25",
                "type": [
                  "pipeline"
                ],
                "prompt": "Explique a diferen√ßa entre interpretar coeficiente e concluir causalidade. D√™ um exemplo de confus√£o comum.",
                "difficulty": 4,
                "tags": [],
                "expected": "Coeficiente mostra associa√ß√£o condicionada √†s features inclu√≠das, n√£o causa. Ex.: coeficiente negativo para 'desconto' n√£o significa que desconto causa churn; pode ser que desconto foi dado a clientes com alto risco.\nEvite decis√µes causais sem experimento ou m√©todos apropriados."
              },
              {
                "id": "ch13_q26",
                "type": [
                  "logistica",
                  "sigmoid"
                ],
                "prompt": "Explique como a escolha de features influencia mais do que a escolha do algoritmo em muitos casos de Regress√£o Log√≠stica.",
                "difficulty": 4,
                "tags": [],
                "expected": "A log√≠stica aprende rela√ß√£o linear; sem features que capturem o sinal (intera√ß√µes, lags, agrega√ß√µes), ela n√£o tem como 'inventar' n√£o linearidade. Boas features podem transformar um problema dif√≠cil em quase linear.\nPor isso EDA e engenharia de features frequentemente d√£o mais ganho que trocar o modelo."
              },
              {
                "id": "ch13_q27",
                "type": [
                  "logistica",
                  "odds"
                ],
                "prompt": "Como avaliar estabilidade do modelo (coeficientes) ao longo do tempo e por que isso importa em produ√ß√£o?",
                "difficulty": 5,
                "tags": [],
                "expected": "Treine em janelas temporais e compare coeficientes e m√©tricas; monitore drift. Mudan√ßas grandes indicam concept drift ou mudan√ßa de dados.\nEstabilidade importa para confiabilidade e governan√ßa: regras de decis√£o podem mudar sem voc√™ perceber."
              },
              {
                "id": "ch13_q28",
                "type": [
                  "logistica",
                  "threshold"
                ],
                "prompt": "Explique 'decision_function' vs 'predict_proba' no sklearn. Quando cada um √© usado?",
                "difficulty": 4,
                "tags": [],
                "expected": "decision_function retorna o score (logit) antes da sigmoide; √© √∫til para ROC e margens. predict_proba retorna probabilidades.\nPara ranking e thresholds customizados, ambos servem; para comunica√ß√£o e custo, probabilidade costuma ser mais intuitiva."
              },
              {
                "id": "ch13_q29",
                "type": [
                  "logistica",
                  "regularizacao"
                ],
                "prompt": "Como escolher features quando h√° muitas dummies (one-hot) e risco de alta dimensionalidade?",
                "difficulty": 5,
                "tags": [],
                "expected": "Use regulariza√ß√£o (L1/Elastic Net), limitar cardinalidade (agrupamento de categorias raras), hashing, e sele√ß√£o baseada em import√¢ncia/estabilidade.\nSempre valide com CV e monitore features que aparecem/desaparecem ao longo do tempo (schema drift)."
              },
              {
                "id": "ch13_q30",
                "type": [
                  "logistica",
                  "multiclass"
                ],
                "prompt": "Explique como fazer valida√ß√£o cruzada estratificada em log√≠stica e por que isso melhora confiabilidade das m√©tricas.",
                "difficulty": 3,
                "tags": [],
                "expected": "Estratifica√ß√£o mant√©m propor√ß√£o de classes em cada dobra, evitando dobras sem positivos. Isso estabiliza m√©tricas como F1 e PR-AUC.\nCom desbalanceamento, CV estratificada √© essencial para tuning e compara√ß√£o justa."
              },
              {
                "id": "ch13_q31",
                "type": [
                  "logistica",
                  "interpretacao"
                ],
                "prompt": "O que √© 'threshold moving' e como ele pode melhorar resultados sem mudar o modelo?",
                "difficulty": 4,
                "tags": [],
                "expected": "√â ajustar o limiar de decis√£o (ex.: 0,5 -> 0,2) para priorizar recall ou precis√£o. Isso muda FP/FN e pode otimizar custo de neg√≥cio.\nFa√ßa usando conjunto de valida√ß√£o e curve PR; documente e monitore em produ√ß√£o."
              },
              {
                "id": "ch13_q32",
                "type": [
                  "logistica",
                  "scaling"
                ],
                "prompt": "Explique como voc√™ detectaria e corrigiria 'training-serving skew' em um modelo log√≠stico.",
                "difficulty": 5,
                "tags": [],
                "expected": "Skew √© diferen√ßa entre features no treino e em produ√ß√£o (ex.: normaliza√ß√£o diferente, categorias novas). Detecte comparando distribui√ß√µes e logs de features.\nCorrija com pipelines compartilhados, versionamento de schema, testes de contrato e valida√ß√µes de data quality na entrada."
              },
              {
                "id": "ch13_q33",
                "type": [
                  "desbalanceamento",
                  "class_weight"
                ],
                "prompt": "Descreva um plano de deploy seguro para um classificador log√≠stico: versionamento, rollback e monitoramento.",
                "difficulty": 5,
                "tags": [],
                "expected": "Empacote o Pipeline (pr√©-processamento+modelo) com vers√£o e metadados. Fa√ßa deploy can√°rio/A-B, monitore m√©tricas online, drift e taxas de erro/alertas.\nTenha rollback para vers√£o anterior e fallback (regra/baseline) se a entrada sair do esperado."
              },
              {
                "id": "ch13_q34",
                "type": [
                  "avaliacao",
                  "roc_pr"
                ],
                "prompt": "Explique como interpretar e comunicar 'import√¢ncia' em log√≠stica: magnitude do coeficiente √© sempre igual a import√¢ncia?",
                "difficulty": 5,
                "tags": [],
                "expected": "Magnitude ajuda, mas depende da escala e da correla√ß√£o entre features. Com padroniza√ß√£o, compara√ß√µes ficam melhores, mas ainda h√° colinearidade.\nUse tamb√©m abla√ß√£o (remover feature), permuta√ß√£o e an√°lise por segmento para uma vis√£o mais confi√°vel."
              },
              {
                "id": "ch13_q35",
                "type": [
                  "logistica",
                  "pipeline"
                ],
                "prompt": "Explique como escolher a janela de rotulagem (label window) e o horizonte de previs√£o para churn/fraude, e o risco de leakage nisso.",
                "difficulty": 5,
                "tags": [],
                "expected": "Voc√™ define 'y=1 se ocorrer evento em H dias'. Features devem ser calculadas apenas at√© o instante de previs√£o. Se voc√™ usa dados ap√≥s esse instante, vaza futuro.\nAlinhe timestamps, use janelas rolling e valide com split temporal para garantir que o modelo simula produ√ß√£o."
              }
            ]
          },
          {
            "chapter": 14,
            "id": "svm",
            "title": "Support Vector Machines (SVM)",
            "keyTopics": [
              "vis√£o geral SVM",
              "executar algoritmo",
              "mapa de decis√£o"
            ],
            "questions": [
              {
                "id": "ch14_q01",
                "type": [
                  "svm"
                ],
                "prompt": "Explique a intui√ß√£o do SVM: margem m√°xima e vetores de suporte. Por que maximizar margem ajuda a generalizar?",
                "difficulty": 3,
                "tags": [],
                "expected": "SVM busca um hiperplano que separa classes com a maior margem poss√≠vel. Vetores de suporte s√£o pontos mais pr√≥ximos da fronteira e determinam a solu√ß√£o.\nMargem maior tende a reduzir vari√¢ncia e melhorar robustez a ru√≠do, aumentando generaliza√ß√£o."
              },
              {
                "id": "ch14_q02",
                "type": [
                  "svm"
                ],
                "prompt": "Compare SVM linear e SVM com kernel. Quando o linear √© suficiente?",
                "difficulty": 3,
                "tags": [],
                "expected": "SVM linear separa com hiperplano no espa√ßo original; kernels permitem separar n√£o linearmente ao mapear para espa√ßo de maior dimens√£o.\nLinear √© suficiente quando as classes j√° s√£o quase separ√°veis linearmente ou quando h√° muitas features (texto, one-hot) e voc√™ precisa de escalabilidade."
              },
              {
                "id": "ch14_q03",
                "type": [
                  "svm"
                ],
                "prompt": "Explique o 'kernel trick' sem matem√°tica pesada. O que ele evita computar explicitamente?",
                "difficulty": 4,
                "tags": [],
                "expected": "O kernel permite calcular similaridade como se voc√™ tivesse mapeado dados para um espa√ßo de alta dimens√£o, sem construir essas features explicitamente.\nIsso evita custo e mem√≥ria de criar o mapeamento e ainda permite fronteiras n√£o lineares."
              },
              {
                "id": "ch14_q04",
                "type": [
                  "pipeline"
                ],
                "prompt": "O que faz o hiperpar√¢metro C no SVM? Explique trade-off entre margem e erros de classifica√ß√£o.",
                "difficulty": 4,
                "tags": [],
                "expected": "C controla penaliza√ß√£o por erros. C alto tenta classificar perfeitamente o treino (margem menor, mais risco de overfitting). C baixo aceita alguns erros para aumentar margem (mais regulariza√ß√£o).\nEscolha C via valida√ß√£o cruzada."
              },
              {
                "id": "ch14_q05",
                "type": [
                  "pr√©-processamento"
                ],
                "prompt": "No kernel RBF, o que significa gamma? Como gamma interage com C?",
                "difficulty": 4,
                "tags": [],
                "expected": "gamma controla o alcance da influ√™ncia de um ponto: gamma alto cria fronteiras muito 'locais' e complexas; gamma baixo cria fronteira mais suave.\nC e gamma juntos controlam complexidade: ambos altos -> overfitting; ambos baixos -> underfitting. Ajuste via grid/random search com CV."
              },
              {
                "id": "ch14_q06",
                "type": [
                  "visualiza√ß√£o"
                ],
                "prompt": "Por que padroniza√ß√£o de features √© praticamente obrigat√≥ria em SVM? D√™ um exemplo do que d√° errado sem isso.",
                "difficulty": 3,
                "tags": [],
                "expected": "SVM depende de dist√¢ncias e produtos internos. Se uma feature est√° em escala maior, ela domina a fronteira.\nEx.: renda (0..1e6) e idade (0..100); sem escala, renda domina. Padronize com StandardScaler dentro de Pipeline para evitar leakage."
              },
              {
                "id": "ch14_q07",
                "type": [
                  "diagn√≥stico"
                ],
                "prompt": "Explique o conceito de 'margem suave' (soft margin). Quando ela √© necess√°ria?",
                "difficulty": 3,
                "tags": [],
                "expected": "Quando dados t√™m ru√≠do ou n√£o s√£o perfeitamente separ√°veis, margem suave permite viola√ß√µes controladas com penalidade (C). Isso evita fronteira extremamente complexa s√≥ para separar poucos pontos.\n√â a configura√ß√£o padr√£o em problemas reais."
              },
              {
                "id": "ch14_q08",
                "type": [
                  "tradeoff"
                ],
                "prompt": "Como o SVM lida com outliers? O que voc√™ faria se poucos outliers estiverem dominando a fronteira?",
                "difficulty": 4,
                "tags": [],
                "expected": "Outliers podem virar vetores de suporte e distorcer a margem. Reduza C (mais regulariza√ß√£o), trate outliers (winsor/remo√ß√£o por regra), use features robustas e verifique qualidade de r√≥tulos.\nSempre valide impacto em CV e analise erros."
              },
              {
                "id": "ch14_q09",
                "type": [
                  "m√©tricas"
                ],
                "prompt": "Explique como obter probabilidades em SVM (predict_proba). Elas s√£o confi√°veis?",
                "difficulty": 5,
                "tags": [],
                "expected": "SVM n√£o produz probabilidades nativas; predict_proba usa calibra√ß√£o (Platt scaling) por tr√°s. Pode funcionar, mas depende de dados e CV.\nSe probabilidades s√£o cr√≠ticas, use calibra√ß√£o expl√≠cita (CalibratedClassifierCV) e valide com Brier/reliability."
              },
              {
                "id": "ch14_q10",
                "type": [
                  "debug"
                ],
                "prompt": "Como tratar classes desbalanceadas em SVM?",
                "difficulty": 4,
                "tags": [],
                "expected": "Use class_weight para penalizar mais a classe rara, avalie com PR-AUC/F1 e ajuste threshold (se usar probabilidades/calibra√ß√£o). Tamb√©m pode usar reamostragem dentro do CV.\nSem isso, o SVM pode favorecer a classe majorit√°ria."
              },
              {
                "id": "ch14_q11",
                "type": [
                  "svm",
                  "margem"
                ],
                "prompt": "Explique a complexidade computacional do SVM com kernel e por que ele pode ficar lento em datasets grandes.",
                "difficulty": 4,
                "tags": [],
                "expected": "SVM com kernel envolve matriz de similaridade entre amostras; custo cresce mais que linear (pode chegar a O(n^2) mem√≥ria/tempo). Em grandes n, fica lento.\nAlternativas: LinearSVC, SGDClassifier, aproxima√ß√µes de kernel (Nystr√∂m, Random Fourier Features) ou modelos de √°rvore/boosting."
              },
              {
                "id": "ch14_q12",
                "type": [
                  "svm",
                  "support_vectors"
                ],
                "prompt": "O que √© 'support vectors ratio' (propor√ß√£o de vetores de suporte) e o que ele pode indicar sobre o modelo?",
                "difficulty": 5,
                "tags": [],
                "expected": "Muitos vetores de suporte podem indicar fronteira complexa/ru√≠do (risco de overfitting) ou separa√ß√£o dif√≠cil. Poucos vetores de suporte podem indicar margem bem definida.\nUse como sinal diagn√≥stico junto com CV e an√°lise de erro."
              },
              {
                "id": "ch14_q13",
                "type": [
                  "svm",
                  "kernel"
                ],
                "prompt": "Como escolher um espa√ßo de features adequado para SVM: exemplos de engenharia de features que ajudam.",
                "difficulty": 4,
                "tags": [],
                "expected": "Crie features que tornem classes mais separ√°veis: escalas corretas, normaliza√ß√£o, intera√ß√µes simples, embeddings para texto, e remo√ß√£o de colunas ruidosas.\nEm muitos casos, melhorar features d√° mais ganho que trocar kernel."
              },
              {
                "id": "ch14_q14",
                "type": [
                  "svm",
                  "C"
                ],
                "prompt": "Explique como validar e ajustar hiperpar√¢metros de SVM de forma correta sem 'p-hacking'.",
                "difficulty": 4,
                "tags": [],
                "expected": "Defina protocolo (StratifiedKFold), use Pipeline com scaler, fa√ßa busca (Grid/Random) em C e gamma, e preserve um teste final intocado.\nReporte m√©dia e desvio das dobras e evite ajustar olhando o teste."
              },
              {
                "id": "ch14_q15",
                "type": [
                  "svm",
                  "gamma"
                ],
                "prompt": "Como visualizar a fronteira de decis√£o de um SVM em 2D e por que isso pode ser enganoso em dados de alta dimens√£o?",
                "difficulty": 4,
                "tags": [],
                "expected": "Em 2D, plote grade de pontos e use decision_function para desenhar contornos. Em alta dimens√£o, proje√ß√µes (PCA) podem ocultar separabilidade real.\nUse visualiza√ß√£o como ferramenta did√°tica, n√£o como prova final; confie em valida√ß√£o e an√°lise de erro."
              },
              {
                "id": "ch14_q16",
                "type": [
                  "svm",
                  "scaling"
                ],
                "prompt": "Compare SVM com Regress√£o Log√≠stica: quando voc√™ escolheria um e n√£o o outro?",
                "difficulty": 4,
                "tags": [],
                "expected": "Log√≠stica fornece probabilidades interpret√°veis e √© forte como baseline; SVM pode separar melhor margens em certos casos, especialmente com kernels n√£o lineares.\nSe voc√™ precisa de probabilidade/calibra√ß√£o e explica√ß√£o simples, log√≠stica; se precisa de fronteira mais flex√≠vel e dados n√£o lineares, SVM (com cuidado de custo)."
              },
              {
                "id": "ch14_q17",
                "type": [
                  "svm",
                  "linear_vs_rbf"
                ],
                "prompt": "Explique 'kernel linear' em dados esparsos (texto/one-hot). Por que ele √© popular?",
                "difficulty": 3,
                "tags": [],
                "expected": "Em texto/one-hot, h√° muitas features e o espa√ßo j√° √© rico; um hiperplano linear costuma ser suficiente. Al√©m disso, m√©todos lineares escalam melhor em n e d.\nLinearSVC ou SGD com hinge loss costuma ser r√°pido e competitivo."
              },
              {
                "id": "ch14_q18",
                "type": [
                  "svm",
                  "complexidade"
                ],
                "prompt": "Descreva um checklist de produ√ß√£o para um modelo SVM: pr√©-processamento, versionamento e monitoramento.",
                "difficulty": 5,
                "tags": [],
                "expected": "Empacote o Pipeline (scaler+svm), registre C/gamma, vers√µes de libs e colunas. Monitore drift de features e taxa de erros/alertas.\nTenha fallback e re-treino peri√≥dico se houver concept drift; SVM √© sens√≠vel a mudan√ßas na escala e distribui√ß√£o."
              }
            ]
          },
          {
            "chapter": 15,
            "id": "svr",
            "title": "Regress√£o de Vetores de Suporte (SVR)",
            "keyTopics": [
              "SVR",
              "padroniza√ß√£o",
              "treino",
              "visualiza√ß√£o resultados"
            ],
            "questions": [
              {
                "id": "ch15_q01",
                "type": [
                  "svr"
                ],
                "prompt": "Explique o que √© SVR (Support Vector Regression) e como ele difere da Regress√£o Linear tradicional.",
                "difficulty": 3,
                "tags": [],
                "expected": "SVR √© a vers√£o do SVM para regress√£o. Em vez de separar classes, ele ajusta uma fun√ß√£o que mant√©m a maioria dos pontos dentro de uma 'banda' de erro (epsilon) e controla complexidade pela margem.\nEle pode capturar n√£o linearidade via kernels, diferente da regress√£o linear simples."
              },
              {
                "id": "ch15_q02",
                "type": [
                  "svr",
                  "padroniza√ß√£o"
                ],
                "prompt": "Explique a perda epsilon-insensitive. Qual √© a intui√ß√£o por tr√°s de 'n√£o penalizar' erros pequenos?",
                "difficulty": 4,
                "tags": [],
                "expected": "Erros menores que epsilon n√£o s√£o penalizados: o modelo foca em ajustar tend√™ncia e ignora pequenas varia√ß√µes/ru√≠do. Isso pode melhorar robustez.\nEpsilon define toler√¢ncia: grande -> mais suavidade/vi√©s; pequeno -> ajuste mais fiel/vari√¢ncia."
              },
              {
                "id": "ch15_q03",
                "type": [
                  "pipeline"
                ],
                "prompt": "O que faz C no SVR? Compare efeito de C em SVR vs em SVM de classifica√ß√£o.",
                "difficulty": 4,
                "tags": [],
                "expected": "C controla penaliza√ß√£o por viola√ß√µes (pontos fora da banda epsilon). C alto for√ßa ajuste aos dados (menos regulariza√ß√£o), C baixo aceita mais viola√ß√µes (mais suavidade).\n√â an√°logo ao SVM: C equilibra ajuste vs margem, mas aqui em erro de regress√£o."
              },
              {
                "id": "ch15_q04",
                "type": [
                  "visualiza√ß√£o"
                ],
                "prompt": "No SVR com RBF, o que gamma controla? Como ele afeta suavidade da curva?",
                "difficulty": 4,
                "tags": [],
                "expected": "gamma alto cria influ√™ncia local, permitindo curvas muito flex√≠veis (risco de overfitting). gamma baixo cria fun√ß√£o mais suave e global.\nAjuste gamma junto com C e epsilon via valida√ß√£o cruzada."
              },
              {
                "id": "ch15_q05",
                "type": [
                  "diagn√≥stico"
                ],
                "prompt": "Por que padroniza√ß√£o √© essencial em SVR? O que pode dar errado sem ela?",
                "difficulty": 3,
                "tags": [],
                "expected": "SVR usa dist√¢ncia/produto interno. Features em escala grande dominam a fun√ß√£o, distorcendo a curva e piorando converg√™ncia.\nUse StandardScaler dentro de Pipeline para treino e predi√ß√£o consistentes, evitando leakage."
              },
              {
                "id": "ch15_q06",
                "type": [
                  "debug"
                ],
                "prompt": "Quando voc√™ escolheria SVR em vez de regress√£o linear, polinomial ou √°rvores?",
                "difficulty": 4,
                "tags": [],
                "expected": "Escolha SVR quando h√° n√£o linearidade moderada, dataset n√£o muito grande e voc√™ quer controle fino via C/epsilon/gamma e boa generaliza√ß√£o.\nSe precisa de interpretabilidade simples, linear; se precisa de regras e intera√ß√µes complexas, √°rvores/boosting; se n √© muito grande, SVR pode ser pesado."
              },
              {
                "id": "ch15_q07",
                "type": [
                  "tradeoff"
                ],
                "prompt": "Explique a complexidade computacional do SVR com kernel. Quando ele se torna impratic√°vel?",
                "difficulty": 4,
                "tags": [],
                "expected": "SVR com kernel pode exigir opera√ß√µes O(n^2) e mem√≥ria alta, ficando lento em milhares/dezenas de milhares de amostras.\nEm grandes dados, use modelos lineares, √°rvores/boosting ou aproxima√ß√µes de kernel."
              },
              {
                "id": "ch15_q08",
                "type": [
                  "avalia√ß√£o"
                ],
                "prompt": "Como avaliar SVR: quais m√©tricas e quais gr√°ficos ajudam a entender erros?",
                "difficulty": 3,
                "tags": [],
                "expected": "Use MAE/RMSE e, se √∫til, R¬≤. Gr√°ficos: real vs predito, res√≠duos vs predito e, em 1D, curva ajustada vs pontos.\nTamb√©m avalie por segmentos/faixas para detectar onde o SVR falha (ex.: extremos)."
              },
              {
                "id": "ch15_q09",
                "type": [
                  "svr",
                  "conceito"
                ],
                "prompt": "Explique como fazer tuning de SVR de forma eficiente. Por que GridSearch ing√™nuo pode ser caro?",
                "difficulty": 5,
                "tags": [],
                "expected": "H√° v√°rios hiperpar√¢metros (C, gamma, epsilon) e combina√ß√µes crescem r√°pido. Use busca aleat√≥ria ou bayesiana, faixas logar√≠tmicas, e CV com poucas dobras inicialmente.\nDepois refine ao redor das melhores regi√µes e preserve teste final intocado."
              },
              {
                "id": "ch15_q10",
                "type": [
                  "svr",
                  "epsilon"
                ],
                "prompt": "Como escolher epsilon? D√™ duas estrat√©gias pr√°ticas.",
                "difficulty": 4,
                "tags": [],
                "expected": "Estrat√©gias: (1) basear em escala do erro aceit√°vel no neg√≥cio (ex.: tolerar ¬±5 unidades); (2) estimar ru√≠do do target (desvio/MAE baseline) e escolher epsilon pr√≥ximo ao ru√≠do.\nTeste alguns valores em CV e observe trade-off entre suavidade e erro."
              },
              {
                "id": "ch15_q11",
                "type": [
                  "svr",
                  "C"
                ],
                "prompt": "Como lidar com outliers em SVR sem simplesmente remov√™-los?",
                "difficulty": 4,
                "tags": [],
                "expected": "Aumente epsilon (ignora pequenas varia√ß√µes), diminua C (mais regulariza√ß√£o), use transforma√ß√µes no target (log) e trate outliers por regra de dom√≠nio.\nValide impacto em CV e verifique se outliers s√£o erros de dado ou eventos reais."
              },
              {
                "id": "ch15_q12",
                "type": [
                  "svr",
                  "kernel"
                ],
                "prompt": "Explique a diferen√ßa entre SVR linear e SVR com RBF. Quando o linear faz sentido?",
                "difficulty": 3,
                "tags": [],
                "expected": "SVR linear aprende fun√ß√£o linear com banda epsilon; √© mais r√°pido e escala melhor. RBF captura n√£o linearidade, mas custa mais.\nLinear faz sentido quando rela√ß√£o √© quase linear e h√° muitas features; RBF quando h√° curvatura e dados n√£o muito grandes."
              },
              {
                "id": "ch15_q13",
                "type": [
                  "svr",
                  "scaling"
                ],
                "prompt": "Como voc√™ integraria SVR em um Pipeline com pr√©-processamento de dados mistos (num√©ricas/categ√≥ricas)?",
                "difficulty": 5,
                "tags": [],
                "expected": "Use ColumnTransformer: num√©ricas -> imputa√ß√£o+StandardScaler; categ√≥ricas -> OneHotEncoder; depois SVR.\nCuidado: OneHot pode criar alta dimensionalidade; SVR RBF pode ficar lento. Considere linear SVR ou reduzir dimensionalidade."
              },
              {
                "id": "ch15_q14",
                "type": [
                  "svr",
                  "tuning"
                ],
                "prompt": "Explique por que SVR pode ser sens√≠vel √† escolha de kernel. Cite alternativas ao RBF.",
                "difficulty": 4,
                "tags": [],
                "expected": "Kernel define forma da fun√ß√£o. RBF √© padr√£o, mas pode overfit/underfit dependendo de gamma. Alternativas: linear (r√°pido), polinomial (curvatura controlada), sigmoid (menos comum).\nEscolha por CV e pelo tipo de rela√ß√£o esperado; evite kernels ex√≥ticos sem evid√™ncia."
              },
              {
                "id": "ch15_q15",
                "type": [
                  "svr",
                  "avaliacao"
                ],
                "prompt": "Como detectar underfitting vs overfitting em SVR olhando treino vs teste e comportamento da curva?",
                "difficulty": 4,
                "tags": [],
                "expected": "Underfitting: erro alto em treino e teste, curva muito lisa e n√£o segue tend√™ncia. Overfitting: treino muito bom, teste ruim, curva muito ondulada (muito local) e muitos vetores de suporte.\nAjuste C/gamma/epsilon e compare por CV."
              },
              {
                "id": "ch15_q16",
                "type": [
                  "svr",
                  "tradeoff"
                ],
                "prompt": "Descreva um checklist de produ√ß√£o para SVR (artefatos, escalas, monitoramento).",
                "difficulty": 5,
                "tags": [],
                "expected": "Salve o Pipeline completo (pr√©-processamento+SVR), registre hiperpar√¢metros e vers√µes. Monitore drift de features/target e aumento de erro.\nSVR √© sens√≠vel a escala: valide inputs em produ√ß√£o e tenha fallback/modelo simples quando entrada estiver fora do suporte."
              }
            ]
          },
          {
            "chapter": 16,
            "id": "knn",
            "title": "K-Nearest Neighbors (K-NN)",
            "keyTopics": [
              "descri√ß√£o K-NN",
              "maldi√ß√£o da dimensionalidade",
              "dataset Bank Note Authentication",
              "importar libs/dados",
              "EDA",
              "pr√©-processamento",
              "padroniza√ß√£o",
              "divis√£o amostra",
              "executar classifica√ß√£o e avaliar"
            ],
            "questions": [
              {
                "id": "ch16_q01",
                "type": [
                  "knn"
                ],
                "prompt": "Explique a intui√ß√£o do K-NN. Por que ele √© chamado de m√©todo 'lazy' e o que isso implica em tempo de predi√ß√£o?",
                "difficulty": 3,
                "tags": [],
                "expected": "K-NN n√£o aprende um modelo param√©trico; ele 'memoriza' os dados e decide pela vizinhan√ßa no momento da predi√ß√£o. Por isso √© 'lazy'.\nImplica: treino r√°pido, mas predi√ß√£o pode ser lenta (precisa calcular dist√¢ncias para muitos pontos), especialmente em grandes datasets."
              },
              {
                "id": "ch16_q02",
                "type": [
                  "knn",
                  "k"
                ],
                "prompt": "Diferencie K-NN para classifica√ß√£o e para regress√£o. Como a decis√£o final √© tomada em cada caso?",
                "difficulty": 3,
                "tags": [],
                "expected": "Classifica√ß√£o: vota entre as classes dos k vizinhos (maioria ou ponderado). Regress√£o: agrega valores (m√©dia/mediana) dos k vizinhos.\nO comportamento depende de k e da m√©trica de dist√¢ncia; em regress√£o, KNN pode suavizar ru√≠do local."
              },
              {
                "id": "ch16_q03",
                "type": [
                  "knn",
                  "padroniza√ß√£o"
                ],
                "prompt": "Por que padroniza√ß√£o √© cr√≠tica em K-NN? D√™ um exemplo do que ocorre se voc√™ n√£o escalar.",
                "difficulty": 3,
                "tags": [],
                "expected": "K-NN depende diretamente de dist√¢ncias; uma feature com escala grande domina e distorce vizinhan√ßa.\nEx.: renda (0..1e6) domina idade (0..100). Use StandardScaler/MinMax dentro de Pipeline para garantir dist√¢ncia significativa."
              },
              {
                "id": "ch16_q04",
                "type": [
                  "dimensionalidade"
                ],
                "prompt": "Compare dist√¢ncias Euclidiana, Manhattan e Minkowski. Quando Manhattan pode ser melhor?",
                "difficulty": 4,
                "tags": [],
                "expected": "Euclidiana (L2) √© padr√£o; Manhattan (L1) soma diferen√ßas absolutas; Minkowski generaliza com par√¢metro p.\nManhattan pode ser melhor em alta dimens√£o ou quando diferen√ßas em cada dimens√£o somam de forma mais robusta, e quando outliers afetam L2."
              },
              {
                "id": "ch16_q05",
                "type": [
                  "dataset",
                  "classifica√ß√£o"
                ],
                "prompt": "Explique o trade-off de k (bias‚Äìvariance). O que acontece com k muito pequeno vs muito grande?",
                "difficulty": 3,
                "tags": [],
                "expected": "k pequeno: baixa bias, alta vari√¢ncia (sens√≠vel a ru√≠do, overfitting). k grande: alta bias, baixa vari√¢ncia (suaviza demais, underfitting).\nEscolha k por valida√ß√£o cruzada e observe curvas de erro vs k."
              },
              {
                "id": "ch16_q06",
                "type": [
                  "pipeline"
                ],
                "prompt": "O que √© 'weighted K-NN'? Quando ponderar por dist√¢ncia ajuda?",
                "difficulty": 4,
                "tags": [],
                "expected": "Em weighted KNN, vizinhos mais pr√≥ximos t√™m maior peso (ex.: 1/d). Ajuda quando h√° ru√≠do e quando vizinhos mais distantes pertencem a outra regi√£o.\nPode melhorar fronteiras e reduzir empates, mas ainda exige scaling e escolha de k."
              },
              {
                "id": "ch16_q07",
                "type": [
                  "eda"
                ],
                "prompt": "Explique a 'maldi√ß√£o da dimensionalidade' e por que ela √© especialmente ruim para K-NN.",
                "difficulty": 4,
                "tags": [],
                "expected": "Em alta dimens√£o, dist√¢ncias ficam menos informativas: pontos tendem a ficar todos 'quase igualmente distantes'. Isso dificulta definir vizinhos reais.\nK-NN perde performance e custo cresce. Mitigue com sele√ß√£o de features, PCA, embeddings ou modelos que lidam melhor com alta dimens√£o."
              },
              {
                "id": "ch16_q08",
                "type": [
                  "padroniza√ß√£o"
                ],
                "prompt": "Como escolher k de forma rigorosa usando valida√ß√£o cruzada estratificada?",
                "difficulty": 4,
                "tags": [],
                "expected": "Use Pipeline (scaler + KNN) e GridSearchCV com StratifiedKFold. Teste uma faixa de k (√≠mpar para evitar empate em bin√°rio) e avalie m√©trica adequada (F1/PR-AUC em desbalanceamento).\nDepois, valide o melhor em teste final."
              },
              {
                "id": "ch16_q09",
                "type": [
                  "valida√ß√£o"
                ],
                "prompt": "Explique por que escolher k √≠mpar √© uma regra pr√°tica em classifica√ß√£o bin√°ria. Quando isso n√£o resolve?",
                "difficulty": 3,
                "tags": [],
                "expected": "√çmpar reduz empates (voto). Mas com classes desbalanceadas ou pesos, empates ainda podem ocorrer; e em multiclass, pode haver empate entre v√°rias classes.\nSolu√ß√µes: pesos por dist√¢ncia, desempate por probabilidade estimada, ou ajustar k/metricas."
              },
              {
                "id": "ch16_q10",
                "type": [
                  "m√©tricas"
                ],
                "prompt": "Como K-NN se comporta com classes desbalanceadas? O que voc√™ faria para melhorar?",
                "difficulty": 4,
                "tags": [],
                "expected": "K-NN tende a favorecer a classe majorit√°ria porque ela domina vizinhan√ßas. Use pesos de classe indiretamente via reamostragem, escolha de m√©trica (recall/PR), ajuste threshold (com probabilidades), e considere radius neighbors.\nTamb√©m avalie por segmento e use features mais discriminantes."
              },
              {
                "id": "ch16_q11",
                "type": [
                  "m√©tricas"
                ],
                "prompt": "Explique o par√¢metro 'metric' e 'p' no KNeighborsClassifier do sklearn. Por que isso importa?",
                "difficulty": 4,
                "tags": [],
                "expected": "metric define a dist√¢ncia; p define a Minkowski (p=1 Manhattan, p=2 Euclidiana). Isso muda forma das vizinhan√ßas e pode afetar performance.\nEscolha por CV; combine com scaling. Dist√¢ncia errada pode destruir separa√ß√£o mesmo com bom k."
              },
              {
                "id": "ch16_q12",
                "type": [
                  "pr√©-processamento"
                ],
                "prompt": "O que s√£o KD-Tree e Ball-Tree no contexto de K-NN? Quando eles aceleram e quando n√£o ajudam?",
                "difficulty": 4,
                "tags": [],
                "expected": "S√£o estruturas para busca de vizinhos. Aceleram em dimens√µes moderadas e datasets grandes. Em alta dimens√£o, benef√≠cio cai (maldi√ß√£o da dimensionalidade) e pode ficar pr√≥ximo de brute-force.\nEscolha algoritmo='auto' ou teste, e considere aproxima√ß√µes para escala."
              },
              {
                "id": "ch16_q13",
                "type": [
                  "reprodutibilidade"
                ],
                "prompt": "Como lidar com features categ√≥ricas em K-NN? Por que one-hot pode piorar a dist√¢ncia?",
                "difficulty": 5,
                "tags": [],
                "expected": "One-hot cria alta dimensionalidade e torna dist√¢ncias Euclidianas menos informativas. Para categ√≥ricas puras, prefira m√©tricas espec√≠ficas (Hamming) ou embeddings.\nAlternativas: usar modelos baseados em √°rvores, ou reduzir dimensionalidade ap√≥s one-hot (SVD/PCA)."
              },
              {
                "id": "ch16_q14",
                "type": [
                  "knn"
                ],
                "prompt": "Explique a diferen√ßa entre normaliza√ß√£o MinMax e padroniza√ß√£o para K-NN. Qual escolher e por qu√™?",
                "difficulty": 3,
                "tags": [],
                "expected": "Ambas resolvem escala. MinMax coloca em [0,1], √∫til quando limites importam; StandardScaler centraliza e usa desvio padr√£o.\nEm geral, StandardScaler funciona bem; MinMax pode ser melhor quando h√° limites naturais e voc√™ quer comparar propor√ß√µes. Teste por CV."
              },
              {
                "id": "ch16_q15",
                "type": [
                  "produ√ß√£o"
                ],
                "prompt": "Como fazer an√°lise de erro em K-NN: que tipos de erro ele tende a cometer e por qu√™?",
                "difficulty": 4,
                "tags": [],
                "expected": "K-NN erra em regi√µes onde classes se misturam, nas bordas e quando h√° ru√≠do/localidade enganosa. Tamb√©m sofre com features irrelevantes.\nAnalise FP/FN por regi√£o (via proje√ß√£o) e por segmento; melhore com sele√ß√£o de features e tuning de dist√¢ncia/k."
              },
              {
                "id": "ch16_q16",
                "type": [
                  "dimensionalidade",
                  "feature_selection"
                ],
                "prompt": "Explique o que √© 'radius neighbors' e quando ele pode ser melhor que k fixo.",
                "difficulty": 5,
                "tags": [],
                "expected": "Em vez de k fixo, voc√™ escolhe um raio e usa todos os pontos dentro. Pode ser melhor quando densidade de dados varia: em regi√µes densas, usa mais vizinhos; em regi√µes esparsas, pode retornar poucos.\nExige escolher raio e lidar com casos sem vizinhos."
              },
              {
                "id": "ch16_q17",
                "type": [
                  "outliers"
                ],
                "prompt": "Como escolher entre K-NN e SVM em um problema de classifica√ß√£o tabular?",
                "difficulty": 4,
                "tags": [],
                "expected": "K-NN √© simples e funciona quando proximidade faz sentido e dimens√£o √© baixa/moderada. SVM √© mais robusto em margens e pode lidar melhor com fronteiras complexas (kernels), mas √© mais caro para tuning.\nCompare via CV e considere custo de predi√ß√£o e interpretabilidade."
              },
              {
                "id": "ch16_q18",
                "type": [
                  "pipeline"
                ],
                "prompt": "Descreva um pipeline completo para o dataset 'Bank Note Authentication': EDA, pr√©-processamento, treino e avalia√ß√£o (conceitualmente).",
                "difficulty": 4,
                "tags": [],
                "expected": "EDA: checar balanceamento, distribui√ß√µes e correla√ß√µes. Pr√©-processar: split estratificado, scaler, e possivelmente sele√ß√£o de features.\nTreinar: KNN com busca por k/metric. Avaliar: matriz de confus√£o, F1/PR-AUC, e an√°lise de erros. Registrar seed e artefatos."
              },
              {
                "id": "ch16_q19",
                "type": [
                  "knn",
                  "distancia"
                ],
                "prompt": "Explique por que K-NN pode ser um bom baseline, mas raramente √© o melhor em produ√ß√£o em grande escala.",
                "difficulty": 4,
                "tags": [],
                "expected": "Como baseline, √© f√°cil e r√°pido de testar. Em produ√ß√£o, predi√ß√£o √© lenta e mem√≥ria cresce com dados. Tamb√©m √© sens√≠vel a drift e √† escolha de features.\nPara escala, preferem-se modelos param√©tricos/ensembles ou aproximados; ou indexa√ß√£o ANN (approx nearest neighbors)."
              },
              {
                "id": "ch16_q20",
                "type": [
                  "knn",
                  "normalizacao"
                ],
                "prompt": "Como detectar drift em um sistema baseado em K-NN? Qual √© o risco espec√≠fico desse tipo de modelo?",
                "difficulty": 5,
                "tags": [],
                "expected": "Se a distribui√ß√£o muda, os 'vizinhos' deixam de representar o novo mundo. O risco √© que o modelo piora sem voc√™ perceber.\nMonitore distribui√ß√µes de features, dist√¢ncia m√©dia aos vizinhos, taxa de erros e qualidade por segmento; atualize base de treinamento periodicamente."
              },
              {
                "id": "ch16_q21",
                "type": [
                  "knn",
                  "escolha_k"
                ],
                "prompt": "Explique como reduzir dimensionalidade antes de K-NN e por que isso ajuda.",
                "difficulty": 4,
                "tags": [],
                "expected": "Use PCA/SVD para projetar em menos dimens√µes com maior vari√¢ncia explicada. Isso torna dist√¢ncias mais informativas e reduz custo.\nFa√ßa dentro de Pipeline e CV para evitar leakage; cuidado para n√£o remover sinal √∫til."
              },
              {
                "id": "ch16_q22",
                "type": [
                  "knn",
                  "ponderado"
                ],
                "prompt": "Quais armadilhas comuns levam K-NN a parecer muito bom no notebook e ruim na pr√°tica?",
                "difficulty": 5,
                "tags": [],
                "expected": "Armadilhas: leakage (escalar antes do split), avaliar com dados muito pr√≥ximos (mesmo usu√°rio em treino/teste), escolher k olhando o teste, e n√£o estratificar.\nTamb√©m: n√£o tratar drift e usar features p√≥s-evento. Corrija com Pipeline, split por grupo/tempo e teste isolado."
              },
              {
                "id": "ch16_q23",
                "type": [
                  "knn",
                  "dimensionalidade"
                ],
                "prompt": "Explique como escolher uma m√©trica de avalia√ß√£o adequada para K-NN em desbalanceamento e como isso influencia escolha de k.",
                "difficulty": 5,
                "tags": [],
                "expected": "Use m√©tricas focadas na classe positiva (recall, precision@recall, PR-AUC, F1). k que maximiza accuracy pode ser diferente do que maximiza F1.\nFa√ßa tuning usando a m√©trica correta e considere threshold/pondera√ß√£o por dist√¢ncia para alinhar ao custo."
              },
              {
                "id": "ch16_q24",
                "type": [
                  "knn",
                  "custo"
                ],
                "prompt": "Como interpretar uma predi√ß√£o de K-NN para explicar ao usu√°rio? D√™ uma forma simples e uma mais t√©cnica.",
                "difficulty": 4,
                "tags": [],
                "expected": "Simples: 'a maioria dos exemplos mais parecidos com este caso pertenciam √† classe X'. T√©cnica: listar k vizinhos, suas dist√¢ncias, classes e votos/pondera√ß√µes.\nIsso d√° transpar√™ncia e ajuda a depurar: se vizinhos parecem errados, a feature space est√° ruim."
              },
              {
                "id": "ch16_q25",
                "type": [
                  "knn",
                  "regressao"
                ],
                "prompt": "Explique como otimizar K-NN para dispositivos/ambiente offline (custo, mem√≥ria e tempo).",
                "difficulty": 5,
                "tags": [],
                "expected": "Reduza tamanho da base (prot√≥tipos, amostragem), comprima features (PCA), use algoritmo eficiente (KD/Ball quando aplic√°vel) e, se poss√≠vel, ANN.\nPr√©-calcule e serialize √≠ndices, e monitore lat√™ncia. Para mobile/offline, muitas vezes um modelo linear ou √°rvore pequena √© mais vi√°vel."
              },
              {
                "id": "ch16_q26",
                "type": [
                  "knn",
                  "outliers"
                ],
                "prompt": "Compare K-NN com modelos baseados em √°rvores em termos de pr√©-processamento e robustez a escala/ru√≠do.",
                "difficulty": 4,
                "tags": [],
                "expected": "K-NN exige scaling e sofre com features irrelevantes/alta dimens√£o. √Årvores n√£o precisam de scaling e lidam melhor com n√£o linearidades e intera√ß√µes.\nPor outro lado, K-NN √© simples e explic√°vel por exemplos. Em tabular geral, √°rvores/boosting costumam vencer em performance."
              }
            ]
          }
        ]
      }
    }
  ]
}